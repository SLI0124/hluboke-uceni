{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "86f2EBR75Itm",
    "tags": []
   },
   "source": [
    "# Deep Learning - Exercise 9\n",
    "\n",
    "This exercise focuses on implementing and utilizing transformer models using the HuggingFace library in conjunction with\n",
    "TensorFlow 2. We'll explore how to leverage pre-trained models for natural language processing tasks.\n",
    "\n",
    "**Core Concepts**\n",
    "\n",
    "- ðŸ¤— HuggingFace library and its ecosystem\n",
    "- ðŸ”§ Integration of HuggingFace models with TensorFlow 2\n",
    "- ðŸ“Š Fine-tuning pre-trained models for specific NLP tasks\n",
    "- ðŸš€ Practical applications of transformer models\n",
    "\n",
    "The lecture is based on [official Huggingface tutorials](https://huggingface.co/transformers/v4.2.2/notebooks.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fi2Jwhs35Itq"
   },
   "source": [
    "[Open in Google colab](https://colab.research.google.com/github/rasvob/VSB-FEI-Deep-Learning-Exercises/blob/main/dl_09.ipynb)\n",
    "[Download from Github](https://github.com/rasvob/VSB-FEI-Deep-Learning-Exercises/blob/main/dl_09.ipynb)\n",
    "\n",
    "##### Remember to set **GPU** runtime in Colab!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.19.0'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow import string as tf_string\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras.layers import LSTM, GRU, Bidirectional\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report, recall_score, precision_score\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import scipy\n",
    "import itertools\n",
    "import string\n",
    "import re\n",
    "import tqdm\n",
    "import io\n",
    "\n",
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.50.3\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from datasets import load_dataset, Dataset\n",
    "from evaluate import load\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification, create_optimizer, AutoModelForSequenceClassification\n",
    "from transformers.keras_callbacks import KerasMetricCallback\n",
    "\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“’ What is the main idea behind transformer models?\n",
    "\n",
    "## The good news is that you already know most of the things from the Attention-focused lecture ðŸ™‚\n",
    "\n",
    "- ðŸ’¡ The main idea behind the transformer architecture is to use **self-attention mechanisms** to capture the\n",
    "  relationships between different words in a sentence\n",
    "- Self-attention allows the model to focus on different parts of the input sequence when processing each word in the\n",
    "  sequence\n",
    "  - This allows the model to take into account the context and dependencies between different words in the sequence,\n",
    "    which is important for many NLP tasks\n",
    "\n",
    "![att](https://github.com/rasvob/VSB-FEI-Deep-Learning-Exercises/blob/main/images/dl_008_meme_02.png?raw=true)\n",
    "\n",
    "## ðŸ”Ž Is there any difference when you compare it to the RNN model? ðŸ”Ž\n",
    "\n",
    "- The main difference between the transformer architecture and recurrent neural networks (RNNs) is the way they handle\n",
    "  sequential data\n",
    "- RNNs process sequential data one element at a time, using hidden states to capture information about the previous\n",
    "  elements in the sequence\n",
    "  - In contrast, the transformer architecture processes the entire sequence at once, using self-attention mechanisms to\n",
    "    capture dependencies between different elements in the sequence\n",
    "- ðŸ’¡ The transformer architecture is **easier parallelizable**.\n",
    "  - ðŸ“Œ The transformer architecture processes the entire sequence at once, it can be trained more efficiently on\n",
    "    parallel hardware like GPUs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# âš¡ We will use the BERT model for sample classification task from the GLUE Benchmark\n",
    "\n",
    "- We will test the model on CoLA dataset which is meant for classification as we need to label every sencente if it is\n",
    "  grammatically correct or not\n",
    "\n",
    "### ðŸ’¡ You can use any of these datasets in this notebook for your experiments\n",
    "\n",
    "- [CoLA](https://nyu-mll.github.io/CoLA/) (Corpus of Linguistic Acceptability) Determine if a sentence is grammatically\n",
    "  correct or not.is a dataset containing sentences labeled grammatically correct or not.\n",
    "- [MNLI](https://arxiv.org/abs/1704.05426) (Multi-Genre Natural Language Inference) Determine if a sentence entails,\n",
    "  contradicts or is unrelated to a given hypothesis. (This dataset has two versions, one with the validation and test\n",
    "  set coming from the same distribution, another called mismatched where the validation and test use out-of-domain\n",
    "  data.)\n",
    "- [MRPC](https://www.microsoft.com/en-us/download/details.aspx?id=52398) (Microsoft Research Paraphrase Corpus)\n",
    "  Determine if two sentences are paraphrases from one another or not.\n",
    "- [QNLI](https://rajpurkar.github.io/SQuAD-explorer/) (Question-answering Natural Language Inference) Determine if the\n",
    "  answer to a question is in the second sentence or not. (This dataset is built from the SQuAD dataset.)\n",
    "- [QQP](https://data.quora.com/First-Quora-Dataset-Release-Question-Pairs) (Quora Question Pairs2) Determine if two\n",
    "  questions are semantically equivalent or not.\n",
    "- [RTE](https://aclweb.org/aclwiki/Recognizing_Textual_Entailment) (Recognizing Textual Entailment) Determine if a\n",
    "  sentence entails a given hypothesis or not.\n",
    "- [SST-2](https://nlp.stanford.edu/sentiment/index.html) (Stanford Sentiment Treebank) Determine if the sentence has a\n",
    "  positive or negative sentiment.\n",
    "- [STS-B](http://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark) (Semantic Textual Similarity Benchmark) Determine the\n",
    "  similarity of two sentences with a score from 1 to 5.\n",
    "- [WNLI](https://cs.nyu.edu/faculty/davise/papers/WinogradSchemas/WS.html) (Winograd Natural Language Inference)\n",
    "  Determine if a sentence with an anonymous pronoun and a sentence with this pronoun replaced are entailed or not. (This\n",
    "  dataset is built from the Winograd Schema Challenge dataset.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You just need to select any task from the list below\n",
    "\n",
    "- ðŸ’¡ The **batch_size** should be set according to your GPU memory\n",
    "\n",
    "### We will use `distilbert-base-uncased` model\n",
    "\n",
    "- ðŸ’¡ The model is primarily aimed at being fine-tuned on tasks that use the whole sentence to make decisions, such as\n",
    "  sequence classification\n",
    "  - This model is uncased: it does not make a difference between english and English\n",
    "- DistilBERT is a transformers model, smaller and faster than BERT, which was pretrained on the same corpus in a\n",
    "  self-supervised fashion, using the BERT base model as a teacher\n",
    "  - This means it was pretrained on the raw texts only, with no humans labelling them in any way with an automatic\n",
    "    process to generate inputs and labels from those texts using the BERT base model\n",
    "  - ðŸ’¡ It \"mimics\" the original BERT outputs using a smaller, less demanding, model\n",
    "- ðŸ“Œ You can check https://huggingface.co/distilbert/distilbert-base-uncased for more details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GLUE_TASKS = [\n",
    "    \"cola\",\n",
    "    \"mnli\",\n",
    "    \"mrpc\",\n",
    "    \"qnli\",\n",
    "    \"qqp\",\n",
    "    \"rte\",\n",
    "    \"sst2\",\n",
    "    \"stsb\",\n",
    "    \"wnli\",\n",
    "]\n",
    "\n",
    "task = \"cola\"\n",
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will use the `datasets` library to download the data and the `evaluate` library to get the metric we need to use for evaluation (to compare our model to the benchmark)\n",
    "\n",
    "- This can be easily done with the `load_dataset` function from datasets and and the `load` function from evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"glue\", task)\n",
    "metric = load(\"glue\", task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The `dataset` object itself is\n",
    "  [DatasetDict](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasetdict), which contains\n",
    "  one key for the training, validation and test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 8551\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 1043\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'label', 'idx'],\n",
       "        num_rows: 1063\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We should always take a look at the example data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': \"Our friends won't buy this analysis, let alone the next one we propose.\",\n",
       " 'label': 1,\n",
       " 'idx': 0}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': [\"Our friends won't buy this analysis, let alone the next one we propose.\",\n",
       "  \"One more pseudo generalization and I'm giving up.\",\n",
       "  \"One more pseudo generalization or I'm giving up.\",\n",
       "  'The more we study verbs, the crazier they get.',\n",
       "  'Day by day the facts are getting murkier.'],\n",
       " 'label': [1, 1, 1, 1, 1],\n",
       " 'idx': [0, 1, 2, 3, 4]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'Bill whistled past the house.', 'label': -1, 'idx': 0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"test\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'The sailors rode the breeze clear of the rocks.',\n",
       " 'label': 1,\n",
       " 'idx': 0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"validation\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The `metric` is an instance of [datasets.Metric](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Metric)\n",
    "\n",
    "- ðŸ’¡ It simplify the process of model evaluation so we don't have to use raw scikit-learn functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EvaluationModule(name: \"glue\", module_type: \"metric\", features: {'predictions': Value(dtype='int64', id=None), 'references': Value(dtype='int64', id=None)}, usage: \"\"\"\n",
       "Compute GLUE evaluation metric associated to each GLUE dataset.\n",
       "Args:\n",
       "    predictions: list of predictions to score.\n",
       "        Each translation should be tokenized into a list of tokens.\n",
       "    references: list of lists of references for each translation.\n",
       "        Each reference should be tokenized into a list of tokens.\n",
       "Returns: depending on the GLUE subset, one or several of:\n",
       "    \"accuracy\": Accuracy\n",
       "    \"f1\": F1 score\n",
       "    \"pearson\": Pearson Correlation\n",
       "    \"spearmanr\": Spearman Correlation\n",
       "    \"matthews_correlation\": Matthew Correlation\n",
       "Examples:\n",
       "\n",
       "    >>> glue_metric = evaluate.load('glue', 'sst2')  # 'sst2' or any of [\"mnli\", \"mnli_mismatched\", \"mnli_matched\", \"qnli\", \"rte\", \"wnli\", \"hans\"]\n",
       "    >>> references = [0, 1]\n",
       "    >>> predictions = [0, 1]\n",
       "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
       "    >>> print(results)\n",
       "    {'accuracy': 1.0}\n",
       "\n",
       "    >>> glue_metric = evaluate.load('glue', 'mrpc')  # 'mrpc' or 'qqp'\n",
       "    >>> references = [0, 1]\n",
       "    >>> predictions = [0, 1]\n",
       "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
       "    >>> print(results)\n",
       "    {'accuracy': 1.0, 'f1': 1.0}\n",
       "\n",
       "    >>> glue_metric = evaluate.load('glue', 'stsb')\n",
       "    >>> references = [0., 1., 2., 3., 4., 5.]\n",
       "    >>> predictions = [0., 1., 2., 3., 4., 5.]\n",
       "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
       "    >>> print({\"pearson\": round(results[\"pearson\"], 2), \"spearmanr\": round(results[\"spearmanr\"], 2)})\n",
       "    {'pearson': 1.0, 'spearmanr': 1.0}\n",
       "\n",
       "    >>> glue_metric = evaluate.load('glue', 'cola')\n",
       "    >>> references = [0, 1]\n",
       "    >>> predictions = [0, 1]\n",
       "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
       "    >>> print(results)\n",
       "    {'matthews_correlation': 1.0}\n",
       "\"\"\", stored examples: 0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You can call its compute method with your predictions and labels directly and it will return a dictionary with the metric(s) value\n",
    "\n",
    "- ðŸ’¡The metric is chosen by the task name we specified so we use the right metric for the benchmark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matthews_correlation': np.float64(0.1536230967599611)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_preds = np.random.randint(0, 2, size=(64,))\n",
    "fake_labels = np.random.randint(0, 2, size=(64,))\n",
    "metric.compute(predictions=fake_preds, references=fake_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the data\n",
    "\n",
    "- Before we can feed those texts to our model, we need to preprocess them. This is done by a Transformers `Tokenizer`\n",
    "  which will (as the name indicates) tokenize the inputs (including converting the tokens to their corresponding IDs in\n",
    "  the pretrained vocabulary) and put it in a format the model expects, as well as generate the other inputs that model\n",
    "  requires\n",
    "\n",
    "- ðŸ’¡ To do all of this, we instantiate our tokenizer with the `AutoTokenizer.from_pretrained` method, which will ensure:\n",
    "\n",
    "  - We get a tokenizer that corresponds to the model architecture we want to use\n",
    "  - We download the vocabulary used when pretraining this specific checkpoint\n",
    "\n",
    "- That vocabulary will be cached, so it's not downloaded again the next time we run the cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Nothing new here - just a regular word2id mapping ðŸ¤—\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 7592, 1010, 2023, 2003, 1037, 6251, 999, 102, 1998, 2023, 6251, 3632, 2007, 2009, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"Hello, this is a sentence!\", \"And this sentence goes with it.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To preprocess our dataset, we will need the names of the columns containing the sentence(s)\n",
    "\n",
    "- The following dictionary keeps track of the correspondence task to column names\n",
    "  - ðŸ’¡ Do you remember that sentence, label, idx dict?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Our friends won't buy this analysis, let alone the next one we propose.\n"
     ]
    }
   ],
   "source": [
    "task_to_keys = {\n",
    "    \"cola\": (\"sentence\", None),\n",
    "    \"mnli\": (\"premise\", \"hypothesis\"),\n",
    "    \"mnli-mm\": (\"premise\", \"hypothesis\"),\n",
    "    \"mrpc\": (\"sentence1\", \"sentence2\"),\n",
    "    \"qnli\": (\"question\", \"sentence\"),\n",
    "    \"qqp\": (\"question1\", \"question2\"),\n",
    "    \"rte\": (\"sentence1\", \"sentence2\"),\n",
    "    \"sst2\": (\"sentence\", None),\n",
    "    \"stsb\": (\"sentence1\", \"sentence2\"),\n",
    "    \"wnli\": (\"sentence1\", \"sentence2\"),\n",
    "}\n",
    "\n",
    "sentence1_key, sentence2_key = task_to_keys[task]\n",
    "if sentence2_key is None:\n",
    "    print(f\"Sentence: {dataset['train'][0][sentence1_key]}\")\n",
    "else:\n",
    "    print(f\"Sentence 1: {dataset['train'][0][sentence1_key]}\")\n",
    "    print(f\"Sentence 2: {dataset['train'][0][sentence2_key]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We just feed them to the tokenizer with the arguments `truncation=True` and `padding='longest'`\n",
    "\n",
    "- ðŸ’¡ This will ensure that an input longer that what the model selected can handle will be truncated to the maximum\n",
    "  length accepted by the model, and all inputs will be padded to the maximum input length to give us a single input\n",
    "  array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    if sentence2_key is None:\n",
    "        return tokenizer(examples[sentence1_key], truncation=True)\n",
    "    return tokenizer(examples[sentence1_key], examples[sentence2_key], truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using this code we can tokenize the sentences in our dataset\n",
    "\n",
    "- To apply this function on all the sentences in our dataset, we just use the map method of our dataset object we\n",
    "  created earlier\n",
    "- ðŸ’¡ This will apply the function on all the elements of all the splits in dataset, so our training, validation and\n",
    "  testing data will be preprocessed in one single command\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012, 102], [101, 2028, 2062, 18404, 2236, 3989, 1998, 1045, 1005, 1049, 3228, 2039, 1012, 102], [101, 2028, 2062, 18404, 2236, 3989, 2030, 1045, 1005, 1049, 3228, 2039, 1012, 102], [101, 1996, 2062, 2057, 2817, 16025, 1010, 1996, 13675, 16103, 2121, 2027, 2131, 1012, 102], [101, 2154, 2011, 2154, 1996, 8866, 2024, 2893, 14163, 8024, 3771, 1012, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess_function(dataset[\"train\"][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns added by tokenizer: ['attention_mask', 'input_ids']\n"
     ]
    }
   ],
   "source": [
    "pre_tokenizer_columns = set(dataset[\"train\"].features)\n",
    "encoded_dataset = dataset.map(preprocess_function, batched=True)\n",
    "tokenizer_columns = list(set(encoded_dataset[\"train\"].features) - pre_tokenizer_columns)\n",
    "print(\"Columns added by tokenizer:\", tokenizer_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ðŸš€ Fine-tuning the model\n",
    "\n",
    "- Now that our data is ready, we can download the pretrained model and fine-tune it\n",
    "  - Since all our tasks are about sentence classification, we use the `TFAutoModelForSequenceClassification` class\n",
    "- ðŸ’¡ The only thing we have to specify is the number of labels for our dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745757981.051662   22949 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6096 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_labels = 3 if task.startswith(\"mnli\") else 1 if task == \"stsb\" else 2\n",
    "if task == \"stsb\":\n",
    "    num_labels = 1\n",
    "elif task.startswith(\"mnli\"):\n",
    "    num_labels = 3\n",
    "else:\n",
    "    num_labels = 2\n",
    "\n",
    "# This next little bit is optional, but will give us cleaner label outputs later\n",
    "# If you're using a task other than CoLA, you will probably need to change these\n",
    "# to match the label names for your task!\n",
    "id2label = {0: \"Invalid\", 1: \"Valid\"}\n",
    "label2id = {val: key for key, val in id2label.items()}\n",
    "\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint, num_labels=num_labels, id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš¡ One of the last steps is to create a TF datasets which will feed the data into the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_key = (\n",
    "    \"validation_mismatched\"\n",
    "    if task == \"mnli-mm\"\n",
    "    else \"validation_matched\"\n",
    "    if task == \"mnli\"\n",
    "    else \"validation\"\n",
    ")\n",
    "\n",
    "tf_train_dataset = model.prepare_tf_dataset(\n",
    "    encoded_dataset[\"train\"],\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "tf_validation_dataset = model.prepare_tf_dataset(\n",
    "    encoded_dataset[validation_key],\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model and specify the optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_distil_bert_for_sequence_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " distilbert (TFDistilBertMa  multiple                  66362880  \n",
      " inLayer)                                                        \n",
      "                                                                 \n",
      " pre_classifier (Dense)      multiple                  590592    \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        multiple                  0 (unused)\n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66955010 (255.41 MB)\n",
      "Trainable params: 66955010 (255.41 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "batches_per_epoch = len(encoded_dataset[\"train\"]) // batch_size\n",
    "total_train_steps = int(batches_per_epoch * num_epochs)\n",
    "\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr=2e-5, num_warmup_steps=0, num_train_steps=total_train_steps\n",
    ")\n",
    "model.compile(optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The last thing we need to define is how to compute the metrics from the predictions\n",
    "\n",
    "- We need to define a function for this, which will just use the metric we loaded earlier\n",
    "\n",
    "  - ðŸ’¡ The only preprocessing we have to do is to take the argmax of our predicted logits\n",
    "\n",
    "- In addition, let's wrap this metric computation function in a `KerasMetricCallback`.\n",
    "  - ðŸ’¡ This callback will compute the metric on the validation set each epoch, including printing it and logging it for\n",
    "    other callbacks like `EarlyStopping`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_predictions):\n",
    "    predictions, labels = eval_predictions\n",
    "    if task != \"stsb\":\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "    else:\n",
    "        predictions = predictions[:, 0]\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "\n",
    "metric_callback = KerasMetricCallback(metric_fn=compute_metrics, eval_dataset=tf_validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš€ We can finally fit the model!\n",
    "\n",
    "- ðŸ’¡ Make sure that you pass the TF datasets, and not the original ones!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1745757993.971267   23121 service.cc:152] XLA service 0x7f942c810140 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1745757993.971297   23121 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 2070, Compute Capability 7.5\n",
      "2025-04-27 14:46:33.976422: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1745757993.991366   23121 cuda_dnn.cc:529] Loaded cuDNN version 90501\n",
      "I0000 00:00:1745757994.107540   23121 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534/534 [==============================] - 78s 105ms/step - loss: 0.5157 - val_loss: 0.4556 - matthews_correlation: 0.4923\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 14:47:41.258798: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534/534 [==============================] - 47s 87ms/step - loss: 0.3178 - val_loss: 0.4630 - matthews_correlation: 0.5373\n",
      "Epoch 3/3\n",
      "  2/534 [..............................] - ETA: 45s - loss: 0.2641"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-27 14:48:28.033899: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534/534 [==============================] - 44s 82ms/step - loss: 0.1890 - val_loss: 0.5479 - matthews_correlation: 0.5099\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x7f967d573c50>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [metric_callback]\n",
    "\n",
    "model.fit(\n",
    "    tf_train_dataset,\n",
    "    validation_data=tf_validation_dataset,\n",
    "    epochs=num_epochs,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we can do inference using our own inputs\n",
    "\n",
    "- Now, let's make up some sentences and see if the model can classify them properly!\n",
    "- The first sentence is valid English, but the second one makes a grammatical mistake.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"The judge told the jurors to think carefully.\",\n",
    "    \"The judge told that the jurors to think carefully.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To feed them into our model, we'll need to tokenize them and then get our model's predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "tokenized = tokenizer(sentences, return_tensors=\"np\", padding=\"longest\")\n",
    "\n",
    "outputs = model(tokenized).logits\n",
    "\n",
    "classifications = np.argmax(outputs, axis=1)\n",
    "print(classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Valid', 'Invalid']\n"
     ]
    }
   ],
   "source": [
    "classifications = [model.config.id2label[output] for output in classifications]\n",
    "print(classifications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ðŸ’¡ But how can we utilize such models in more std. task setup?\n",
    "\n",
    "- I have data in Pandas DF and what is next?\n",
    "- Let's try such use-case together!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame({'text': dataset['train']['text'], 'labels': dataset['train']['label']})\n",
    "df_test = pd.DataFrame({'text': dataset['test']['text'], 'labels': dataset['test']['label']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  labels\n",
       "0  I rented I AM CURIOUS-YELLOW from my video sto...       0\n",
       "1  \"I Am Curious: Yellow\" is a risible and preten...       0\n",
       "2  If only to avoid making this type of film in t...       0\n",
       "3  This film was probably inspired by Godard's Ma...       0\n",
       "4  Oh, brother...after hearing about this ridicul...       0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 2), (25000, 2))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "0    12500\n",
       "1    12500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ok, Pandas seems ready ðŸ™‚\n",
    "\n",
    "- The easies way is to wrap the `Pandas DataFrame` in HF `Dataset` object and proceed with their API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hf_df_train = Dataset.from_pandas(df_train)\n",
    "hf_df_test = Dataset.from_pandas(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can split the data into train and validation subsets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = hf_df_train.train_test_split(test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 20000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then we can add the validation set to the dataset as well\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_tst = ds['test']\n",
    "ds['valid'] = ds_tst\n",
    "ds['test'] = hf_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 20000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['text', 'labels'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '\"A Thief in the Night\" is a film that was generally ignored by movie fans at large due to its low-budget (which was obvious) and its subject matter--the Rapture of true Christian church and the fate of those left behind. Nevertheless, it was a gripping story that held the viewer and definitely made him or her review their relationship with Jesus Christ. It touched everyone--showing even a pastor who preached the Word, but did not believe it, knowing exactly why he was left behind. This movie, and its sequel \"Distant Thunder,\" are must see movies. Even with the new \"Left Behind\" series coming out, telling the same story with a much higher budget, the impact is still the same--\"A Thief in the Night\" broke the ground of this genre and will always be remembered.',\n",
       " 'labels': 1}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'it is of course very nice to see improvements on Turkish movie industry, however, i would have expected something more creative from Togan Gokbakar. starting from the script, which i believe it was not a wise written one as some may think. especially the cheesiness of the dialogs, which were putting the audience in a position that, as if they were not smart enough to understand the situations, which, most of the times makes the movie unbearable. it also has an obvious ending; you can easily guess the murderer from the beginning. the weakest part of the scenario is that the impossibility of seriously mentally ill patients to act like normal people, like professionals right away!!!did they ever search for the possibility of patients who are on heavy medicals, to act like professionals and use all the medical terms that even normal people cannot use?????!!!!!!also in the scene where staff was searching for the most dangerous patient, with out any weapon to protect themselves was another weird point of the film. and that scene was so suitable for \"Dikkat Sahan Cikabilir\" title!! those are not the only weak parts of the movie. there were also a lot of preciosities in the film. the depiction of the most dangerous patient was an exact copy from Hannibal, also appearance of Togan in the very end is obviously the worst mistake that he could have done in his first movie! the fuss about the greatness of the movie and the interviews that actor\\'s gave just made people to be curious and force them to see it. Gen is a total disappointment. i would have wonder, if Sahan was not this famous, would Togan be able to shoot this movie, with this much of budget amount?? i hope Togan would realize that it is not fashionable to play in a role as a director as he said in an interview. it was Hitchcock who did it wisely and Night Shyamalan continued it successfully! he should be aware of the fact that he is not Hitchcock nor Shyamalan yet!!!!hoping him to be more careful and creative next time in this big industry!',\n",
       " 'labels': 0}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['valid'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'I love sci-fi and am willing to put up with a lot. Sci-fi movies/TV are usually underfunded, under-appreciated and misunderstood. I tried to like this, I really did, but it is to good TV sci-fi as Babylon 5 is to Star Trek (the original). Silly prosthetics, cheap cardboard sets, stilted dialogues, CG that doesn\\'t match the background, and painfully one-dimensional characters cannot be overcome with a \\'sci-fi\\' setting. (I\\'m sure there are those of you out there who think Babylon 5 is good sci-fi TV. It\\'s not. It\\'s clichÃ©d and uninspiring.) While US viewers might like emotion and character development, sci-fi is a genre that does not take itself seriously (cf. Star Trek). It may treat important issues, yet not as a serious philosophy. It\\'s really difficult to care about the characters here as they are not simply foolish, just missing a spark of life. Their actions and reactions are wooden and predictable, often painful to watch. The makers of Earth KNOW it\\'s rubbish as they have to always say \"Gene Roddenberry\\'s Earth...\" otherwise people would not continue watching. Roddenberry\\'s ashes must be turning in their orbit as this dull, cheap, poorly edited (watching it without advert breaks really brings this home) trudging Trabant of a show lumbers into space. Spoiler. So, kill off a main character. And then bring him back as another actor. Jeeez! Dallas all over again.',\n",
       " 'labels': 0}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['test'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš¡ Finally, we need to tokenize the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c928c155ac9d4558a56ed85488757820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b060e91aabc45d6afc452688e7053a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc1f3042a1d14acc91d753af57eaba66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-cased\")\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=True, truncation=True, max_length=300, return_tensors=\"tf\")\n",
    "\n",
    "\n",
    "tokenized_datasets = ds.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# âš  The label columns must be named as **labels** because the model expects this name!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 20000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['text', 'labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 5000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"distilbert-base-cased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "tf_train_dataset = model.prepare_tf_dataset(\n",
    "    tokenized_datasets[\"train\"],\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "tf_test_dataset = model.prepare_tf_dataset(\n",
    "    tokenized_datasets['test'],\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "tf_valid_dataset = model.prepare_tf_dataset(\n",
    "    tokenized_datasets['valid'],\n",
    "    shuffle=False,\n",
    "    batch_size=batch_size,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš€ Let's train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_distil_bert_for_sequence_classification_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " distilbert (TFDistilBertMa  multiple                  65190912  \n",
      " inLayer)                                                        \n",
      "                                                                 \n",
      " pre_classifier (Dense)      multiple                  590592    \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        multiple                  0 (unused)\n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65783042 (250.94 MB)\n",
      "Trainable params: 65783042 (250.94 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "batches_per_epoch = len(tokenized_datasets[\"train\"]) // batch_size\n",
    "total_train_steps = int(batches_per_epoch * num_epochs)\n",
    "\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr=2e-5, num_warmup_steps=0, num_train_steps=total_train_steps\n",
    ")\n",
    "model.compile(optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 571s 443ms/step - loss: 0.2967 - val_loss: 0.2430\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x7f94c01446e0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    tf_train_dataset,\n",
    "    validation_data=tf_valid_dataset,\n",
    "    epochs=num_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_test = np.array(ds['test']['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let the model predict the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 264s 169ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(tf_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred_f = np.argmax(y_pred.logits, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we can compute an `accuracy_score` like we are used to ðŸ™‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90492"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true=y_test, y_pred=y_pred_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dude](https://github.com/rasvob/VSB-FEI-Deep-Learning-Exercises/blob/main/images/dl_008_meme_01.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# âœ… Tasks for the lecture (2p)\n",
    "\n",
    "- HuggingFace has a very easy-to-use [Pipelines API](https://huggingface.co/docs/transformers/en/main_classes/pipelines)\n",
    "- Check the documentation how to use it\n",
    "- Select any model from the [collection](https://huggingface.co/models) which is able to classify text (you can use\n",
    "  again the `distilbert-base-cased`)\n",
    "- Use the Pipelines API to classify the IMDB dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"prajjwal1/bert-tiny\"\n",
    "# model_name = \"distilbert-base-cased\"\n",
    "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2, from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = [text[:4000] for text in ds['test']['text']]\n",
    "test_labels = ds['test']['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings = tokenizer(\n",
    "    test_texts,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=512,\n",
    "    return_tensors=\"tf\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(encodings),\n",
    "    test_labels\n",
    ")).batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 415s 1s/step\n"
     ]
    }
   ],
   "source": [
    "outputs = model.predict(tf_dataset)\n",
    "logits = outputs.logits\n",
    "predictions = tf.argmax(logits, axis=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8907\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy_score(test_labels, predictions):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(test_labels, predictions)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Negative', 'Positive'],\n",
    "            yticklabels=['Negative', 'Positive'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89     12500\n",
      "           1       0.91      0.86      0.89     12500\n",
      "\n",
      "    accuracy                           0.89     25000\n",
      "   macro avg       0.89      0.89      0.89     25000\n",
      "weighted avg       0.89      0.89      0.89     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.8906292835529501\n",
      "Accuracy: 0.89072\n",
      "Precision: 0.8920206303666052\n",
      "Recall: 0.89072\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 Score:\", f1_score(test_labels, predictions, average='weighted'))\n",
    "print(\"Accuracy:\", accuracy_score(test_labels, predictions))\n",
    "print(\"Precision:\", precision_score(test_labels, predictions, average='weighted'))\n",
    "print(\"Recall:\", recall_score(test_labels, predictions, average='weighted'))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ds4_03.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "hluboke-uceni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
