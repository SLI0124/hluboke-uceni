{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86f2EBR75Itm",
    "tags": []
   },
   "source": [
    "# Deep Learning - Exercise 7\n",
    "\n",
    "The aim of this exercise is to learn how to build unsupervised word embeddings using the Word2Vec Skip-Gram method and implement recurrent neural networks (RNNs) for text generation using Harry Potter books as our dataset.\n",
    "\n",
    "**Core Concepts**\n",
    "* 🧠 Word2Vec Skip-Gram model for creating word embeddings\n",
    "* 📚 Harry Potter corpus for training word embeddings\n",
    "* 🔤 Analyzing word relationships in embedding space\n",
    "* ⚡ Text generation using character-based RNNs\n",
    "* 📝 Creating Harry Potter style stories with generative models\n",
    "\n",
    "The Word2Vec approach is based on [official Keras tutorial](https://www.tensorflow.org/tutorials/text/word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fi2Jwhs35Itq"
   },
   "source": [
    "[Open in Google colab](https://colab.research.google.com/github/rasvob/VSB-FEI-Deep-Learning-Exercises/blob/main/dl_07.ipynb)\n",
    "[Download from Github](https://github.com/rasvob/VSB-FEI-Deep-Learning-Exercises/blob/main/dl_07.ipynb)\n",
    "\n",
    "##### Remember to set **GPU** runtime in Colab!"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T18:16:33.319303Z",
     "start_time": "2025-03-31T18:16:33.315717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "pxC6GcdPCWNe",
    "outputId": "e5ef9b03-cfcf-4d0b-ba55-08e1d973b097",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:16:35.476676Z",
     "start_time": "2025-03-31T18:16:33.491703Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow import string as tf_string\n",
    "from tensorflow.keras.layers import TextVectorization, LSTM, GRU, Bidirectional\n",
    "\n",
    "from sklearn.model_selection import train_test_split  #\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import scipy\n",
    "import itertools\n",
    "import string\n",
    "import re\n",
    "import tqdm\n",
    "import io\n",
    "\n",
    "tf.version.VERSION"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-31 20:16:33.733709: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743444993.758777   13199 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743444993.767537   13199 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.18.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "wHbSkNYuCWNf",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:16:35.497407Z",
     "start_time": "2025-03-31T18:16:35.493705Z"
    }
   },
   "source": [
    "def show_history(history):\n",
    "    plt.figure()\n",
    "    for key in history.history.keys():\n",
    "        plt.plot(history.epoch, history.history[key], label=key)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "eq_DUyv4CWNg",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:16:35.553786Z",
     "start_time": "2025-03-31T18:16:35.549492Z"
    }
   },
   "source": [
    "SEED = 13"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDxW9xs3CWNh"
   },
   "source": [
    "# 🔎 What is word embedding?\n",
    "* Why do we use it?\n",
    "* Do we need to train our own embedding?\n",
    "* Do the embedding have any other usage beside ANN applications?\n",
    "\n",
    "# 📒 Word2Vec\n",
    "\n",
    "## 💡 There are two approaches for a Word2Vec embedding training\n",
    "\n",
    "* **Continuous bag-of-words model**:\n",
    "    * predicts the middle word based on surrounding context words.\n",
    "    * the context consists of a few words before and after the current (middle) word.\n",
    "    * this architecture is called a bag-of-words model as the order of words in the context is not important.\n",
    "\n",
    "* **Continuous skip-gram model**:\n",
    "    * predicts words within a certain range before and after the current word in the same sentence.\n",
    "    * **we will use this as it is easier concept to grasp**\n",
    "\n",
    "![w2v](https://github.com/rasvob/VSB-FEI-Deep-Learning-Exercises/blob/main/images/dl_07_skip.png?raw=true)\n",
    "  \n",
    "* 📌 Bag-of-words model predicts a word given the neighboring context\n",
    "* 📌 Skip-gram model predicts the context (or neighbors) of a word, given the word itself\n",
    "\n",
    "* The model is trained on skip-grams, which are n-grams that allow tokens to be skipped (see the diagram below for an example).\n",
    "* 💡 The context of a word can be represented through a set of skip-gram pairs of `(target_word, context_word)` where `context_word` appears in the neighboring context of target_word.\n",
    "\n",
    "## 🔎 What is the difference between Word2Vec or other embeddings and GPT-like models?\n",
    "* The core idea is the same: Both models need a way to represent words as dense vectors in a continuous vector space\n",
    "* The models serve different purposes and operate in different ways\n",
    "    * GPT-like models are focused more on vector-to-vector tasks - generating of text answers\n",
    "        * e.g. question answering, translation, text completion, ....\n",
    "    * Traditional models focus rather on vector-to-scalar tasks - classification\n",
    "        * e.g. sentiment analysis\n",
    "* Word2Vec embeddings generate fixed-size vector representations for words based on their co-occurrence statistics within a context window\n",
    "    * These representations do not capture the context in which the word appears in a specific sentence or document\n",
    "    * 💡 Word2Vec embeddings can be trained on relatively smaller corpora and still capture meaningful semantic relationships between words\n",
    "* GPT models capture contextual understanding by considering the entire preceding context when generating each token in a sequence\n",
    "    * This allows them to generate more contextually relevant responses and understand nuances in language better\n",
    "    * 💡 The model to learn rich representations of language and capture long-range dependencies\n",
    "    * 💡 GPT models need exposure to a diverse range of linguistic patterns and contexts, which typically requires a large dataset\n",
    "* 📌 A \"crossover\" between both approaches are transformer models models like BERT\n",
    "    * It uses a masked language model (MLM) objective, where random words in a sentence are masked, and the model is trained to predict these masked words based on the surrounding context\n",
    "    * Additionally, BERT also uses a next sentence prediction (NSP) objective during pre-training to learn sentence-level relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UyBTkxSCWNi"
   },
   "source": [
    "## We will demonstrate the Word2Vec working using single sentence\n",
    "\n",
    "* The context words for each of the 8 words of this sentence are defined by a window size.\n",
    "    * 💡 The window size determines the span of words on either side of a target_word that can be considered a context word.\n",
    "\n",
    "![w2v_tab](https://github.com/rasvob/VSB-FEI-Deep-Learning-Exercises/blob/main/images/dl_07_tab.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bNCX4lWeCWNj"
   },
   "source": [
    "## In the first step we will tokenize the sentence"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aeyZwPQDCWNj",
    "outputId": "62d8302e-0968-4b12-f2bf-e0584c05df21",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:16:35.620780Z",
     "start_time": "2025-03-31T18:16:35.616188Z"
    }
   },
   "source": [
    "sentence = \"The wide road shimmered in the hot sun\"\n",
    "tokens = list(sentence.lower().split())\n",
    "print(len(tokens))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOILryFECWNk"
   },
   "source": [
    "## Now we can build the vocabulary and mapping WORD -> ID"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W1yMUTx3CWNl",
    "outputId": "92b57b55-dbc3-489a-9e61-46aded2a2f12",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:16:35.704496Z",
     "start_time": "2025-03-31T18:16:35.700678Z"
    }
   },
   "source": [
    "vocab, index = {}, 1  # start indexing from 1\n",
    "vocab['<pad>'] = 0  # add a padding token\n",
    "for token in tokens:\n",
    "    if token not in vocab:\n",
    "        vocab[token] = index\n",
    "        index += 1\n",
    "vocab_size = len(vocab)\n",
    "print(vocab)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<pad>': 0, 'the': 1, 'wide': 2, 'road': 3, 'shimmered': 4, 'in': 5, 'hot': 6, 'sun': 7}\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "id": "JB56DtUaCWNl"
   },
   "source": [
    "## It is common to also build also the inverse mapping ID -> WORD"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PKZN8KayCWNl",
    "outputId": "3bd27fe9-5cb8-49c1-99b5-9ce227434b4e",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:16:35.768046Z",
     "start_time": "2025-03-31T18:16:35.764440Z"
    }
   },
   "source": [
    "inverse_vocab = {index: token for token, index in vocab.items()}\n",
    "print(inverse_vocab)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<pad>', 1: 'the', 2: 'wide', 3: 'road', 4: 'shimmered', 5: 'in', 6: 'hot', 7: 'sun'}\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D91zpcOeCWNl"
   },
   "source": [
    "## So int-encoded sentences will look like this one"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dGPeCk1oCWNm",
    "outputId": "edf9ed2d-d8a9-497b-d077-b5fd5ca21d16",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:16:35.811105Z",
     "start_time": "2025-03-31T18:16:35.807815Z"
    }
   },
   "source": [
    "example_sequence = [vocab[word] for word in tokens]\n",
    "print(example_sequence)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 1, 6, 7]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p7fSwDAaCWNm"
   },
   "source": [
    "## 📌 We can use the [tf.keras.preprocessing.sequence.skipgrams](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence) to generate skip-gram pairs\n",
    "\n",
    "*  We will generate skip-grams from the example_sequence with a given window_size from tokens in the range [0, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z3aw-mIWCWNm",
    "outputId": "108cece3-a8fc-4cf9-c0de-ba94063ad2ce",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:16:35.863955Z",
     "start_time": "2025-03-31T18:16:35.859789Z"
    }
   },
   "source": [
    "window_size = 2\n",
    "positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "    example_sequence,\n",
    "    vocabulary_size=vocab_size,\n",
    "    window_size=window_size,\n",
    "    negative_samples=0,\n",
    "    seed=int(SEED))\n",
    "print(len(positive_skip_grams))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFFtrU2JCWNn"
   },
   "source": [
    "## ⚡ Let's take a look at some skip-gram examples"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mtm5VEYbCWNn",
    "outputId": "388a918a-41b8-41bd-ae73-57cf9b0ee659",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:16:35.911902Z",
     "start_time": "2025-03-31T18:16:35.907858Z"
    }
   },
   "source": [
    "for target, context in positive_skip_grams[:5]:\n",
    "    print(f\"({target}, {context}): ({inverse_vocab[target]}, {inverse_vocab[context]})\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4): (the, shimmered)\n",
      "(4, 1): (shimmered, the)\n",
      "(5, 4): (in, shimmered)\n",
      "(7, 1): (sun, the)\n",
      "(4, 3): (shimmered, road)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "id": "Dd_u4Kv0CWNn"
   },
   "source": [
    "## 📒 Negative sampling for one skip-gram\n",
    "\n",
    "* The skip-gram function returns all positive skip-gram pairs by sliding over a given window span\n",
    "\n",
    "### 💡 But we also need some negative examples to train the model as well\n",
    "\n",
    "## 🔎 How can we generate such samples?\n",
    "* To produce additional skip-gram pairs that would serve as negative samples for training, you need to sample random words from the vocabulary\n",
    "* Use the `tf.random.log_uniform_candidate_sampler` function to sample `num_ns` number of negative samples for a given target word in a window\n",
    "    * 💡 You can call the function on one skip-grams's target word and pass the context word as true class to exclude it from being sampled"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dkXmtRIHCWNo",
    "outputId": "674a6d23-a42b-463e-b039-d8f956645a86",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:16:36.472215Z",
     "start_time": "2025-03-31T18:16:35.958127Z"
    }
   },
   "source": [
    "# Get target and context words for one positive skip-gram.\n",
    "target_word, context_word = positive_skip_grams[0]\n",
    "\n",
    "# Set the number of negative samples per positive context.\n",
    "num_ns = 4\n",
    "\n",
    "context_class = tf.reshape(tf.constant(context_word, dtype=\"int64\"), (1, 1))\n",
    "negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "    true_classes=context_class,  # class that should be sampled as 'positive'\n",
    "    num_true=1,  # each positive skip-gram has 1 positive context class\n",
    "    num_sampled=num_ns,  # number of negative context words to sample\n",
    "    unique=True,  # all the negative samples should be unique\n",
    "    range_max=vocab_size,  # pick index of the samples from [0, vocab_size]\n",
    "    seed=SEED,  # seed for reproducibility\n",
    "    name=\"negative_sampling\"  # name of this operation\n",
    ")\n",
    "print(inverse_vocab[target_word], inverse_vocab[context_word])\n",
    "print(negative_sampling_candidates)\n",
    "print([inverse_vocab[index.numpy()] for index in negative_sampling_candidates])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shimmered\n",
      "tf.Tensor([3 0 4 2], shape=(4,), dtype=int64)\n",
      "['road', '<pad>', 'shimmered', 'wide']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743444996.245295   13199 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6096 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "DYVfjQOACWNo",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:16:36.525341Z",
     "start_time": "2025-03-31T18:16:36.518856Z"
    }
   },
   "source": [
    "# Reduce a dimension so you can use concatenation (in the next step).\n",
    "squeezed_context_class = tf.squeeze(context_class, 1)\n",
    "\n",
    "# Concatenate a positive context word with negative sampled words.\n",
    "context = tf.concat([squeezed_context_class, negative_sampling_candidates], 0)\n",
    "\n",
    "# Label the first context word as `1` (positive) followed by `num_ns` `0`s (negative).\n",
    "label = tf.constant([1] + [0] * num_ns, dtype=\"int64\")\n",
    "target = target_word"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R3c2SurfCWNo",
    "outputId": "ccc495f5-63b1-49d1-d5cd-731ed23d1529",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:16:36.591913Z",
     "start_time": "2025-03-31T18:16:36.581454Z"
    }
   },
   "source": [
    "print(f\"target_index    : {target}\")\n",
    "print(f\"target_word     : {inverse_vocab[target_word]}\")\n",
    "print(f\"context_indices : {context}\")\n",
    "print(f\"context_words   : {[inverse_vocab[c.numpy()] for c in context]}\")\n",
    "print(f\"label           : {label}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_index    : 1\n",
      "target_word     : the\n",
      "context_indices : [4 3 0 4 2]\n",
      "context_words   : ['shimmered', 'road', '<pad>', 'shimmered', 'wide']\n",
      "label           : [1 0 0 0 0]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3LfabL3JCWNo"
   },
   "source": [
    "# The whole process can be illustrated with this example\n",
    "\n",
    "![w2v_example](https://github.com/rasvob/VSB-FEI-Deep-Learning-Exercises/blob/main/images/dl_07_example.png?raw=true)\n",
    "\n",
    "## Skip-gram sampling table\n",
    "* A large dataset means larger vocabulary with higher number of more frequent words such as stopwords\n",
    "* 💡 Training examples obtained from sampling commonly occurring words (such as the, is, on) don't add much useful information for the model\n",
    "    * Subsampling of frequent words as a helpful practice to improve embedding quality\n",
    "\n",
    "### `sampling_table[i]` denotes the probability of sampling the `i-th` most common word in a dataset."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5FTWg4HMCWNp",
    "outputId": "3239b5c0-9c4b-44c0-8c22-6216e13767ef",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:16:36.641909Z",
     "start_time": "2025-03-31T18:16:36.637868Z"
    }
   },
   "source": [
    "sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(size=10)\n",
    "print(sampling_table)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00315225 0.00315225 0.00547597 0.00741556 0.00912817 0.01068435\n",
      " 0.01212381 0.01347162 0.01474487 0.0159558 ]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNQf3V4ACWNp"
   },
   "source": [
    "## ⚡ Compile all the steps described above into a function that can be called on a list of vectorized sentences obtained from any text dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "DUUfaehfCWNp",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:16:36.713199Z",
     "start_time": "2025-03-31T18:16:36.707560Z"
    }
   },
   "source": [
    "# Generates skip-gram pairs with negative sampling for a list of sequences\n",
    "# (int-encoded sentences) based on window size, number of negative samples\n",
    "# and vocabulary size.\n",
    "def generate_training_data(sequences, window_size, num_ns, vocab_size, seed):\n",
    "    # Elements of each training example are appended to these lists.\n",
    "    targets, contexts, labels = [], [], []\n",
    "\n",
    "    # Build the sampling table for `vocab_size` tokens.\n",
    "    sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(vocab_size)\n",
    "\n",
    "    # Iterate over all sequences (sentences) in the dataset.\n",
    "    for sequence in tqdm.tqdm(sequences):\n",
    "\n",
    "        # Generate positive skip-gram pairs for a sequence (sentence).\n",
    "        positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "            sequence,\n",
    "            vocabulary_size=vocab_size,\n",
    "            sampling_table=sampling_table,\n",
    "            window_size=window_size,\n",
    "            seed=int(SEED),\n",
    "            negative_samples=0)\n",
    "\n",
    "        # Iterate over each positive skip-gram pair to produce training examples\n",
    "        # with a positive context word and negative samples.\n",
    "        for target_word, context_word in positive_skip_grams:\n",
    "            context_class = tf.expand_dims(tf.constant([context_word], dtype=\"int64\"), 1)\n",
    "            negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
    "                true_classes=context_class,\n",
    "                num_true=1,\n",
    "                num_sampled=num_ns,\n",
    "                unique=True,\n",
    "                range_max=vocab_size,\n",
    "                seed=int(SEED),\n",
    "                name=\"negative_sampling\")\n",
    "\n",
    "            # Build context and label vectors (for one target word)\n",
    "            context = tf.concat([tf.squeeze(context_class, 1), negative_sampling_candidates], 0)\n",
    "            label = tf.constant([1] + [0] * num_ns, dtype=\"int64\")\n",
    "\n",
    "            # Append each element from the training example to global lists.\n",
    "            targets.append(target_word)\n",
    "            contexts.append(context)\n",
    "            labels.append(label)\n",
    "\n",
    "    return targets, contexts, labels"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7_JuNJ_SCWNp"
   },
   "source": [
    "## 📒 Now we can download the Harry Potter and the Sorcerer's Stone book and train our own embedding"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LgDx5EPyCWNp",
    "outputId": "06b2d16a-deae-4f4c-c076-e6cafa27d201",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:16:36.761179Z",
     "start_time": "2025-03-31T18:16:36.757291Z"
    }
   },
   "source": [
    "path_to_file = tf.keras.utils.get_file('hp1.txt',\n",
    "                                       'https://raw.githubusercontent.com/rasvob/VSB-FEI-Deep-Learning-Exercises/main/datasets/hp1.txt')"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BmplVFG1CWNq"
   },
   "source": [
    "## First 50 lines of the book"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ee0HhXaICWNq",
    "outputId": "31ed61d0-4a7f-4b37-ca34-04df1add2e61",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:16:36.813417Z",
     "start_time": "2025-03-31T18:16:36.807007Z"
    }
   },
   "source": [
    "with open(path_to_file) as f:\n",
    "    lines = f.read().splitlines()\n",
    "for line in lines[:50]:\n",
    "    print(line)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry Potter and the Sorcerer's Stone\n",
      "\n",
      "\n",
      "CHAPTER ONE\n",
      "\n",
      "THE BOY WHO LIVED\n",
      "\n",
      "Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say\n",
      "that they were perfectly normal, thank you very much. They were the last\n",
      "people you'd expect to be involved in anything strange or mysterious,\n",
      "because they just didn't hold with such nonsense.\n",
      "\n",
      "Mr. Dursley was the director of a firm called Grunnings, which made\n",
      "drills. He was a big, beefy man with hardly any neck, although he did\n",
      "have a very large mustache. Mrs. Dursley was thin and blonde and had\n",
      "nearly twice the usual amount of neck, which came in very useful as she\n",
      "spent so much of her time craning over garden fences, spying on the\n",
      "neighbors. The Dursleys had a small son called Dudley and in their\n",
      "opinion there was no finer boy anywhere.\n",
      "\n",
      "The Dursleys had everything they wanted, but they also had a secret, and\n",
      "their greatest fear was that somebody would discover it. They didn't\n",
      "think they could bear it if anyone found out about the Potters. Mrs.\n",
      "Potter was Mrs. Dursley's sister, but they hadn't met for several years;\n",
      "in fact, Mrs. Dursley pretended she didn't have a sister, because her\n",
      "sister and her good-for-nothing husband were as unDursleyish as it was\n",
      "possible to be. The Dursleys shuddered to think what the neighbors would\n",
      "say if the Potters arrived in the street. The Dursleys knew that the\n",
      "Potters had a small son, too, but they had never even seen him. This boy\n",
      "was another good reason for keeping the Potters away; they didn't want\n",
      "Dudley mixing with a child like that.\n",
      "\n",
      "When Mr. and Mrs. Dursley woke up on the dull, gray Tuesday our story\n",
      "starts, there was nothing about the cloudy sky outside to suggest that\n",
      "strange and mysterious things would soon be happening all over the\n",
      "country. Mr. Dursley hummed as he picked out his most boring tie for\n",
      "work, and Mrs. Dursley gossiped away happily as she wrestled a screaming\n",
      "Dudley into his high chair.\n",
      "\n",
      "None of them noticed a large, tawny owl flutter past the window.\n",
      "\n",
      "At half past eight, Mr. Dursley picked up his briefcase, pecked Mrs.\n",
      "Dursley on the cheek, and tried to kiss Dudley good-bye but missed,\n",
      "because Dudley was now having a tantrum and throwing his cereal at the\n",
      "walls. \"Little tyke,\" chortled Mr. Dursley as he left the house. He got\n",
      "into his car and backed out of number four's drive.\n",
      "\n",
      "It was on the corner of the street that he noticed the first sign of\n",
      "something peculiar -- a cat reading a map. For a second, Mr. Dursley\n",
      "didn't realize what he had seen -- then he jerked his head around to\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WXeaqB6ACWNq"
   },
   "source": [
    "# 🚀 We will employ the *TextLineDataset* from the TF data API\n",
    "* It allows us to easily load text file line by line and preprocess it\n",
    "* We will skip the book title and blank lines, then we will remove the CHAPTER XYZ lines as the information is not useful\n",
    "    * Then we can transform the text into lowercase and remove the punctuation\n",
    "    * We will use the punctuation from the `re` package"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "cG85o2bnCWNq",
    "outputId": "3665bdaa-3abd-4a6e-8b36-1ebb50677da6",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:16:36.861973Z",
     "start_time": "2025-03-31T18:16:36.857647Z"
    }
   },
   "source": [
    "re.escape(string.punctuation)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"\\\\#\\\\$%\\\\&\\'\\\\(\\\\)\\\\*\\\\+,\\\\-\\\\./:;<=>\\\\?@\\\\[\\\\\\\\\\\\]\\\\^_`\\\\{\\\\|\\\\}\\\\~'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "kvg5Wkw0CWNr",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:16:36.995784Z",
     "start_time": "2025-03-31T18:16:36.917891Z"
    }
   },
   "source": [
    "text_ds = tf.data.TextLineDataset(path_to_file).skip(1).filter(lambda x: tf.cast(tf.strings.length(x), bool)).filter(\n",
    "    lambda y: not tf.strings.regex_full_match(y, 'CHAPTER.*')).map(lambda z: tf.strings.lower(z)).map(\n",
    "    lambda a: tf.strings.regex_replace(a, f'[{re.escape(string.punctuation)}]', ''))"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJldVATBCWNr"
   },
   "source": [
    "## Here is our pre-processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sBnWZuHqCWNr",
    "outputId": "300892e8-6a2e-45f7-cb3d-d19cb36e7913",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:16:37.049360Z",
     "start_time": "2025-03-31T18:16:37.010690Z"
    }
   },
   "source": [
    "for element in text_ds.take(10).as_numpy_iterator():\n",
    "    print(element)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'the boy who lived'\n",
      "b'mr and mrs dursley of number four privet drive were proud to say'\n",
      "b'that they were perfectly normal thank you very much they were the last'\n",
      "b'people youd expect to be involved in anything strange or mysterious'\n",
      "b'because they just didnt hold with such nonsense'\n",
      "b'mr dursley was the director of a firm called grunnings which made'\n",
      "b'drills he was a big beefy man with hardly any neck although he did'\n",
      "b'have a very large mustache mrs dursley was thin and blonde and had'\n",
      "b'nearly twice the usual amount of neck which came in very useful as she'\n",
      "b'spent so much of her time craning over garden fences spying on the'\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0ZqrLT0CWNr"
   },
   "source": [
    "## The TF dataset works as a data stream\n",
    "* 💡 The TF dataset uses standard map/reduce API\n",
    "    * 🔎 How do we iterate over data stream?\n",
    "    * 🔎 How to count elements?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JcVAHGxGCWNs"
   },
   "source": [
    "## Total number of lines in the book"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UWueMiS-CWNs",
    "outputId": "46b07dc0-5fa7-4861-c666-ece1a0b30c5e",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:16:39.199335Z",
     "start_time": "2025-03-31T18:16:37.061061Z"
    }
   },
   "source": [
    "text_ds.map(lambda x: tf.cast(tf.strings.length(x), tf.int32)).reduce(0, lambda x, y: x + 1).numpy()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int32(7628)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "id": "X_ZGG5MCCWNs"
   },
   "source": [
    "## Total length of the text"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9a-yuCdGCWNs",
    "outputId": "dc8e8536-ea32-4736-f810-d6ee09679be1",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:16:40.596573Z",
     "start_time": "2025-03-31T18:16:39.212160Z"
    }
   },
   "source": [
    "text_ds.map(lambda x: tf.cast(tf.strings.length(x), tf.int32)).reduce(0, lambda x, y: x + y).numpy()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int32(405596)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9HZe2s4nCWNs"
   },
   "source": [
    "## Average length of the text"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y7TmTPYaCWNt",
    "outputId": "7ea217a5-59c8-453f-914b-682fcf35186b",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:16:42.963932Z",
     "start_time": "2025-03-31T18:16:40.607929Z"
    }
   },
   "source": [
    "text_ds.map(lambda x: tf.cast(tf.strings.length(x), tf.int32)).reduce(0, lambda x, y: x + y).numpy() // text_ds.map(\n",
    "    lambda x: tf.cast(tf.strings.length(x), tf.int32)).reduce(0, lambda x, y: x + 1).numpy()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int32(53)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3oqqn79CWNt"
   },
   "source": [
    "# Now we can setup the `TextVectorization` layer for integer encoding of the tokens\n",
    "* 💡 It is the same layer as in the sentiment analysis excercise"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "W3eMr9K6CWNu",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:16:44.006520Z",
     "start_time": "2025-03-31T18:16:42.973680Z"
    }
   },
   "source": [
    "sequence_length = 15\n",
    "vectorize_layer = keras.layers.TextVectorization(max_tokens=None, output_mode='int',\n",
    "                                                 output_sequence_length=sequence_length)\n",
    "vectorize_layer.adapt(text_ds.batch(1024))"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KnYrjKcUCWNu"
   },
   "source": [
    "## Vocabulary example"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4AlJnPJ9CWNu",
    "outputId": "2ad5b3a6-982f-4a69-e53d-d187d129f4a8",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:16:44.027726Z",
     "start_time": "2025-03-31T18:16:44.015891Z"
    }
   },
   "source": [
    "inverse_vocab = vectorize_layer.get_vocabulary()\n",
    "print(inverse_vocab[:20])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', np.str_('the'), np.str_('and'), np.str_('to'), np.str_('a'), np.str_('he'), np.str_('of'), np.str_('harry'), np.str_('was'), np.str_('it'), np.str_('in'), np.str_('his'), np.str_('you'), np.str_('said'), np.str_('had'), np.str_('i'), np.str_('on'), np.str_('at'), np.str_('that')]\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "id": "aVB7SgVzCWNu"
   },
   "source": [
    "## Number of tokens in vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GS4Ok3YQCWNu",
    "outputId": "01b531df-5f5f-418b-b035-e0583222a56e",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:16:44.141059Z",
     "start_time": "2025-03-31T18:16:44.079162Z"
    }
   },
   "source": [
    "vocab_size = len(vectorize_layer.get_vocabulary())\n",
    "vocab_size"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6036"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "sT8KTJVcCWNv",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:16:44.186069Z",
     "start_time": "2025-03-31T18:16:44.182451Z"
    }
   },
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wINK8DCDCWNv"
   },
   "source": [
    "## 💡 The `unbatch` works in a similar way as the `ravel` in numpy\n",
    "* i.e. flattening `(n, 1)` shaped array into `(n,)` shaped one\n",
    "    * e.g. `[[5], [0], [2]]` -> `[5, 0, 2]`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "KuR4G_9LCWNv",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:16:44.337447Z",
     "start_time": "2025-03-31T18:16:44.243189Z"
    }
   },
   "source": [
    "text_vector_ds = text_ds.batch(1024).prefetch(AUTOTUNE).map(vectorize_layer).unbatch()"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BxcGZGbOCWNw",
    "outputId": "222d1dc3-bf38-4f18-e809-6ac4ea9ceaa5",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:16:44.513624Z",
     "start_time": "2025-03-31T18:16:44.348219Z"
    }
   },
   "source": [
    "for x in text_vector_ds.take(5).as_numpy_iterator():\n",
    "    print(x)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   2  141   74 1071    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n",
      "[ 148    3  258  223    7  616  366  646  534   32 1272    4  157    0\n",
      "    0]\n",
      "[  19   20   32 1574  974 1128   13   68  155   20   32    2  143    0\n",
      "    0]\n",
      "[ 131  469  789    4   30 1608   11  165  471  102 1421    0    0    0\n",
      "    0]\n",
      "[ 140   20   63   56  835   24  497 1844    0    0    0    0    0    0\n",
      "    0]\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGTyn-ElCWNw"
   },
   "source": [
    "## ⚡ We can take a look at number of sequences generated and some examples of the data as well"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SZxeKaPRCWNw",
    "outputId": "26807787-9996-4786-d7ec-81ef83628580",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:16:45.714769Z",
     "start_time": "2025-03-31T18:16:44.523879Z"
    }
   },
   "source": [
    "sequences = list(text_vector_ds.as_numpy_iterator())\n",
    "len(sequences)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7628"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7isT3s0QCWNw"
   },
   "source": [
    "### 🔎 Why are there the `0` ids?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N398KvFlCWNw",
    "outputId": "ac985fdb-c4f5-4b60-fb79-4604a65ecb0f",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:16:45.731471Z",
     "start_time": "2025-03-31T18:16:45.727335Z"
    }
   },
   "source": [
    "for seq in sequences[:5]:\n",
    "    print(f\"{seq} => {[inverse_vocab[i] for i in seq]}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   2  141   74 1071    0    0    0    0    0    0    0    0    0    0\n",
      "    0] => [np.str_('the'), np.str_('boy'), np.str_('who'), np.str_('lived'), '', '', '', '', '', '', '', '', '', '', '']\n",
      "[ 148    3  258  223    7  616  366  646  534   32 1272    4  157    0\n",
      "    0] => [np.str_('mr'), np.str_('and'), np.str_('mrs'), np.str_('dursley'), np.str_('of'), np.str_('number'), np.str_('four'), np.str_('privet'), np.str_('drive'), np.str_('were'), np.str_('proud'), np.str_('to'), np.str_('say'), '', '']\n",
      "[  19   20   32 1574  974 1128   13   68  155   20   32    2  143    0\n",
      "    0] => [np.str_('that'), np.str_('they'), np.str_('were'), np.str_('perfectly'), np.str_('normal'), np.str_('thank'), np.str_('you'), np.str_('very'), np.str_('much'), np.str_('they'), np.str_('were'), np.str_('the'), np.str_('last'), '', '']\n",
      "[ 131  469  789    4   30 1608   11  165  471  102 1421    0    0    0\n",
      "    0] => [np.str_('people'), np.str_('youd'), np.str_('expect'), np.str_('to'), np.str_('be'), np.str_('involved'), np.str_('in'), np.str_('anything'), np.str_('strange'), np.str_('or'), np.str_('mysterious'), '', '', '', '']\n",
      "[ 140   20   63   56  835   24  497 1844    0    0    0    0    0    0\n",
      "    0] => [np.str_('because'), np.str_('they'), np.str_('just'), np.str_('didnt'), np.str_('hold'), np.str_('with'), np.str_('such'), np.str_('nonsense'), '', '', '', '', '', '', '']\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tV9ZPYA8CWNx"
   },
   "source": [
    "## 🚀 Finally we can create the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZGJL8cJUCWNx",
    "outputId": "4193d5da-2126-4eb1-ccd0-f47525d5e5dd",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:17:44.989308Z",
     "start_time": "2025-03-31T18:16:45.840749Z"
    }
   },
   "source": [
    "targets, contexts, labels = generate_training_data(\n",
    "    sequences=sequences,\n",
    "    window_size=2,\n",
    "    num_ns=4,\n",
    "    vocab_size=vocab_size,\n",
    "    seed=int(SEED))\n",
    "\n",
    "targets = np.array(targets)\n",
    "contexts = np.array(contexts)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print('\\n')\n",
    "print(f\"targets.shape: {targets.shape}\")\n",
    "print(f\"contexts.shape: {contexts.shape}\")\n",
    "print(f\"labels.shape: {labels.shape}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7628/7628 [00:48<00:00, 157.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "targets.shape: (38615,)\n",
      "contexts.shape: (38615, 5)\n",
      "labels.shape: (38615, 5)\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZCrVWdi8CWNx",
    "outputId": "16683007-e092-4fb4-c3a4-af0ecbc9ddf3",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:17:45.001504Z",
     "start_time": "2025-03-31T18:17:44.996639Z"
    }
   },
   "source": [
    "targets"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1071, 1071,  534, ...,  606,   45,  606])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G5rPQqI7CWNx",
    "outputId": "c84306b9-52c6-4b59-bf8e-b84eef486c86",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:17:45.050430Z",
     "start_time": "2025-03-31T18:17:45.045853Z"
    }
   },
   "source": [
    "contexts"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 141,  373,   10,  631,  168],\n",
       "       [  74,  612,    0,    1, 1509],\n",
       "       [1272,   72, 1017,  234,    1],\n",
       "       ...,\n",
       "       [  45,   23,    6,  113,   71],\n",
       "       [ 606,    2, 1219,   94, 2821],\n",
       "       [  32,  851,    4, 1903, 1611]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pkr0tZSHCWNx",
    "outputId": "8e08857b-a47e-4706-c703-e039ae1f83d6",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:17:45.258285Z",
     "start_time": "2025-03-31T18:17:45.253790Z"
    }
   },
   "source": [
    "labels"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-OqDYcqDCWNy"
   },
   "source": [
    "## We will form the dataset using TF data API as well"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AmK2FdYGCWNy",
    "outputId": "7cd157c7-a9fd-4c98-da73-844fce9b2fab",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:17:45.305841Z",
     "start_time": "2025-03-31T18:17:45.286101Z"
    }
   },
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "dataset = tf.data.Dataset.from_tensor_slices(((targets.reshape(-1, 1), contexts), labels))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "print(dataset)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_BatchDataset element_spec=((TensorSpec(shape=(64, 1), dtype=tf.int64, name=None), TensorSpec(shape=(64, 5), dtype=tf.int64, name=None)), TensorSpec(shape=(64, 5), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "neRfOJcuCWNy"
   },
   "source": [
    "## Performance tweaks\n",
    "* When the GPU is working on forward / backward propagation on the current batch, we want the CPU to process the next batch of data so that it is immediately ready\n",
    "* 💡 As the most expensive part of the computer, we want the GPU to be fully used all the time during training\n",
    "    * We call this consumer / producer overlap, where the consumer is the GPU and the producer is the CPU\n",
    "\n",
    "* With `tf.data`, you can do this with a simple call to `dataset.prefetch(N)` at the end of the pipeline (after batching).\n",
    "    * 💡 This will always prefetch `N` batches of data and make sure that there is always `N` batches ready."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "KlRVmQJqCWNy",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:17:45.376111Z",
     "start_time": "2025-03-31T18:17:45.369193Z"
    }
   },
   "source": [
    "dataset = dataset.cache().prefetch(buffer_size=AUTOTUNE)"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wuomzGDFCWNy"
   },
   "source": [
    "## 🚀 The final step is to define and train the model\n",
    "* We will use 2 `Embedding` layers\n",
    "    * One for the **target word** and one for the **context words**\n",
    "* Finally the dot product of the Embedding outputs will be computed to combine the vectors and the result will be taken as an output"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "gPKbbf57CWNz",
    "outputId": "719705f9-e67b-4aa6-badd-dd205fe8bf26",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:17:46.101557Z",
     "start_time": "2025-03-31T18:17:45.424735Z"
    }
   },
   "source": [
    "embedding_dim = 50\n",
    "\n",
    "target_input = keras.layers.Input((1,))\n",
    "context_input = keras.layers.Input((num_ns + 1,))\n",
    "\n",
    "emb_w2v = keras.layers.Embedding(vocab_size, embedding_dim, name=\"w2v_embedding\",\n",
    "                                 embeddings_initializer='glorot_uniform')(target_input)\n",
    "emb_ctx = keras.layers.Embedding(vocab_size, embedding_dim, name=\"ctx_embedding\",\n",
    "                                 embeddings_initializer='glorot_uniform')(context_input)\n",
    "\n",
    "dots = keras.layers.dot([emb_w2v, emb_ctx], axes=2)\n",
    "\n",
    "fl = keras.layers.Flatten()(dots)\n",
    "\n",
    "# out = keras.layers.Dense(num_ns+1, activation='linear')(fl)\n",
    "\n",
    "model = keras.Model(inputs=[target_input, context_input], outputs=fl)\n",
    "\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)       \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape     \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m   Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to     \u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)         │          \u001B[38;5;34m0\u001B[0m │ -                 │\n",
       "│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m5\u001B[0m)         │          \u001B[38;5;34m0\u001B[0m │ -                 │\n",
       "│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ w2v_embedding       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m, \u001B[38;5;34m50\u001B[0m)     │    \u001B[38;5;34m301,800\u001B[0m │ input_layer[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m] │\n",
       "│ (\u001B[38;5;33mEmbedding\u001B[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ctx_embedding       │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m5\u001B[0m, \u001B[38;5;34m50\u001B[0m)     │    \u001B[38;5;34m301,800\u001B[0m │ input_layer_1[\u001B[38;5;34m0\u001B[0m]… │\n",
       "│ (\u001B[38;5;33mEmbedding\u001B[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot (\u001B[38;5;33mDot\u001B[0m)           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m, \u001B[38;5;34m5\u001B[0m)      │          \u001B[38;5;34m0\u001B[0m │ w2v_embedding[\u001B[38;5;34m0\u001B[0m]… │\n",
       "│                     │                   │            │ ctx_embedding[\u001B[38;5;34m0\u001B[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001B[38;5;33mFlatten\u001B[0m)   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m5\u001B[0m)         │          \u001B[38;5;34m0\u001B[0m │ dot[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m]         │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ w2v_embedding       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">301,800</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ ctx_embedding       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">301,800</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dot</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ w2v_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ ctx_embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dot[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m603,600\u001B[0m (2.30 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">603,600</span> (2.30 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m603,600\u001B[0m (2.30 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">603,600</span> (2.30 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 839
    },
    "id": "ew7csmmUCWNz",
    "outputId": "864ef1cd-fb4a-489f-bc2e-f11a8a61d3be",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:17:46.147210Z",
     "start_time": "2025-03-31T18:17:46.142891Z"
    }
   },
   "source": [
    "tf.keras.utils.plot_model(model)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "9nTDySX8CWNz",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:17:46.216720Z",
     "start_time": "2025-03-31T18:17:46.195392Z"
    }
   },
   "source": [
    "model.compile(optimizer=keras.optimizers.AdamW(),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KhgNd1IDCWNz",
    "outputId": "c6a2e1d0-11c3-4b2a-c96e-ac29d50c51e6",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:19:11.081484Z",
     "start_time": "2025-03-31T18:17:46.271427Z"
    }
   },
   "source": [
    "history = model.fit(dataset, epochs=50)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1743445066.837889   13263 service.cc:148] XLA service 0x7fc12c004070 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1743445066.837925   13263 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 2070, Compute Capability 7.5\n",
      "I0000 00:00:1743445064.550606   13263 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m  1/603\u001B[0m \u001B[37m━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[1m-804s\u001B[0m -1335879us/step - accuracy: 0.2031 - loss: 1.6095"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1743445064.931121   13263 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 3ms/step - accuracy: 0.2408 - loss: 1.6038\n",
      "Epoch 2/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.3926 - loss: 1.4908\n",
      "Epoch 3/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.4915 - loss: 1.3543\n",
      "Epoch 4/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.5984 - loss: 1.2069\n",
      "Epoch 5/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.6860 - loss: 1.0579\n",
      "Epoch 6/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.7514 - loss: 0.9170\n",
      "Epoch 7/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.8015 - loss: 0.7893\n",
      "Epoch 8/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.8381 - loss: 0.6766\n",
      "Epoch 9/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.8664 - loss: 0.5791\n",
      "Epoch 10/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.8878 - loss: 0.4961\n",
      "Epoch 11/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9077 - loss: 0.4261\n",
      "Epoch 12/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9246 - loss: 0.3673\n",
      "Epoch 13/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9376 - loss: 0.3181\n",
      "Epoch 14/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9492 - loss: 0.2768\n",
      "Epoch 15/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9574 - loss: 0.2420\n",
      "Epoch 16/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9647 - loss: 0.2126\n",
      "Epoch 17/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9704 - loss: 0.1876\n",
      "Epoch 18/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m-1s\u001B[0m -1042us/step - accuracy: 0.9745 - loss: 0.1664\n",
      "Epoch 19/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9789 - loss: 0.1482\n",
      "Epoch 20/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9815 - loss: 0.1327\n",
      "Epoch 21/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9832 - loss: 0.1194\n",
      "Epoch 22/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9856 - loss: 0.1079\n",
      "Epoch 23/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9865 - loss: 0.0981\n",
      "Epoch 24/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9877 - loss: 0.0896\n",
      "Epoch 25/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9882 - loss: 0.0823\n",
      "Epoch 26/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9885 - loss: 0.0759\n",
      "Epoch 27/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9889 - loss: 0.0704\n",
      "Epoch 28/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9892 - loss: 0.0657\n",
      "Epoch 29/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9896 - loss: 0.0615\n",
      "Epoch 30/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9897 - loss: 0.0579\n",
      "Epoch 31/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9900 - loss: 0.0548\n",
      "Epoch 32/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9900 - loss: 0.0520\n",
      "Epoch 33/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9901 - loss: 0.0496\n",
      "Epoch 34/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9900 - loss: 0.0475\n",
      "Epoch 35/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9900 - loss: 0.0456\n",
      "Epoch 36/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m-1s\u001B[0m -1100us/step - accuracy: 0.9900 - loss: 0.0440\n",
      "Epoch 37/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9900 - loss: 0.0425\n",
      "Epoch 38/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 2ms/step - accuracy: 0.9899 - loss: 0.0412\n",
      "Epoch 39/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9899 - loss: 0.0401\n",
      "Epoch 40/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9900 - loss: 0.0391\n",
      "Epoch 41/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 2ms/step - accuracy: 0.9899 - loss: 0.0382\n",
      "Epoch 42/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9899 - loss: 0.0374\n",
      "Epoch 43/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9899 - loss: 0.0367\n",
      "Epoch 44/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9899 - loss: 0.0361\n",
      "Epoch 45/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - accuracy: 0.9900 - loss: 0.0355\n",
      "Epoch 46/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9901 - loss: 0.0350\n",
      "Epoch 47/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9902 - loss: 0.0345\n",
      "Epoch 48/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9902 - loss: 0.0341\n",
      "Epoch 49/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9902 - loss: 0.0338\n",
      "Epoch 50/50\n",
      "\u001B[1m603/603\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 3ms/step - accuracy: 0.9902 - loss: 0.0334\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "mPkKL7ClCWNz",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:20:44.483245Z",
     "start_time": "2025-03-31T18:20:44.303814Z"
    }
   },
   "source": [
    "show_history(history)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAHWCAYAAAD6oMSKAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAXrJJREFUeJzt3Xl4VIX59vHvzGQnkISEfV+TQMIqsogiiAsCWkC0VkTQWlHQ1uWFtr9WxaWgFVto1WpRVEQtitCyuCGKgGwiSICw74QlCWHLnpnz/nGSkECATJY5M5P7c13nmjNnzvJMHgI3Z7UZhmEgIiIiIj7PbnUBIiIiIlI1FOxERERE/ISCnYiIiIifULATERER8RMKdiIiIiJ+QsFORERExE8o2ImIiIj4CQU7ERERET8RYHUB5eFyuSgoKMBut2Oz2awuR0RERMRjDMPA5XIREBCA3X75fXI+EewKCgpISkqyugwRERERyyQmJhIUFHTZeXwi2BWl08TERBwOR7Vtx+l0kpSUVO3bkcpTr3yL+uU71CvfoV75jsr2qmj5K+2tAx8JdkWHXx0Oh0f+8HpqO1J56pVvUb98h3rlO9Qr31HZXpXndDRdPCEiIiLiJxTsRERERPyEgp2IiIiIn/CJc+xERESkfJxOJ/n5+VaXISU4nU4AcnJyyjzHLjAwsMrOk1SwExER8QOGYXDs2DFOnTpldSlyAcMwCAgI4MCBA5e8ACIyMpKGDRtW+n69CnYiIiJ+oCjU1a9fn7CwMN3Q34sYhkF2djahoaEX9cUwDLKysjhx4gQAjRo1qtS2FOxERER8nNPpLA510dHRVpcjFyh6ckRISEiZgTs0NBSAEydOUL9+/UodltXFEyIiIj6u6Jy6sLAwiyuRiirqXWXPj3Q72K1fv55x48bRt29fYmNjWbp06RWXycvL429/+xv9+/cnISGBAQMG8Omnn1aoYBERESmbDr/6rqrqnduHYrOysoiNjWXEiBFMmDChXMv89re/JT09nRdffJHmzZuTmpqKy+Vyu1gRERERuTS3g12/fv3o169fuef//vvvWb9+PUuXLiUyMhKApk2burtZEREREbmCaj/HbtmyZSQkJDBz5kyuvfZabr75Zl566SVycnKqe9MiIiIibvPl+wBW+1Wxhw4dYsOGDQQHB/Paa6+RkZHB5MmTOXXqFFOmTHFrXUU3+KsuReuv7u1I5alXvkX98h3qle8o2Sun04lhGMWDr1mxYgVvvPEGu3btwm6306VLF/7v//6P5s2bA+atXF5++WVWrVpFXl4erVu35umnn6Zz586AuRPp9ddfZ+fOnYSFhXHVVVfxz3/+E4C4uDj++c9/MnDgwOLt9ejRgz/84Q8MHz6cw4cPM3DgQF599VU+/PBDNm/ezLPPPkv//v15/vnn+fHHHzlz5gzNmjXjoYceYsiQIcXrcblcvPPOO8ydO5ejR48SExPDXXfdxbhx47jvvvto06YNTz/9dHFP0tPTuf7663nrrbfo3bt3qZ9BUe+K+lmSO7+P1R7sDMPAZrPxyiuvULt2bQB+//vf89hjj/HMM88QEhJS7nUlJSVVV5mWbEcqT73yLeqX71CvfEdRrwICAsjOzvbJc9hPnTrF3XffTbt27cjOzuaNN97gkUce4eOPPyYnJ4dRo0ZRr149Xn31VaKjo9m+fTtZWVlkZWWxYsUKnnjiCe6//36effZZCgoKWLlyJVlZWcXrz83NLfXeMAzy8vLIysoqPoL4yiuv8Pjjj/PMM88QFBTE6dOnad++Pffeey+1atVi5cqVTJo0ifr165OQkADA9OnTmT9/Pk8++SRdunQhLS2N/fv3k5WVxW233cZLL73EY489RlBQEADz5s2jXr16dOrUqVQ9RTXm5+ezffv2Sv0sqz3Y1atXjwYNGhSHOoA2bdoU3yG7ZcuW5V5XYmJilT1yoyxOp5OkpKRq345UnnrlW9Qv36Fe+Y6SvcrPz+fAgQOEhoaW2mFiGAbZ+Z7d+xoa6HD7Cs+hQ4eWev/SSy/Ru3dvUlJS2LhxIxkZGXz66afF5+rHxcUVzztr1ixuvfVWnnzyyeJpXbp0KbW+4ODgUreCsdlsBAUFERYWVvzzGjNmzEV1jBs3rni8ffv2rF27lm+//Zarr76ac+fO8dFHH/HnP/+ZkSNHAhAbG8s111wDwJAhQ3j55ZdZvXo1t9xyC9nZ2SxevJjhw4dTq1ati34GdrudwMBA2rZte9FOr6Jel0e1B7tu3brxxRdfkJmZWfxF9u3bh91up2HDhm6ty+FwVOtfNLat82m46wccnV/WX2g+orr/TEjVUr98h3rlOxwOBy6XC5vNVjyAGepGvrmGDQcyPFrPVS2i+GRcb7fC3f79+5kxYwY///wzGRkZxYcujx07xvbt2+nQoQNRUVFlLrt9+3buvPPOy26v5M/lwmlF0xMSEkrN43Q6+de//sUXX3zB8ePHyc/PJy8vr/jpEfv27SMvL4/evcv+riEhIdx2223MmzePQYMGkZyczK5du3jjjTfKnL+olsr+7rl98URmZibJyckkJycDcPjwYZKTk0lJSQFg2rRpTJw4sXj+IUOGEBkZyR/+8Ad2797N+vXr+etf/8qIESPcOgzrCbbvX6bJ9rdh33dWlyIiIlJpvnJXu3HjxnH69GleeOEFPvnkE+bOnQuYFzFcKStc6XObzXbReYcFBQUXzXfhzZ3ffvtt3n//fX7961/z/vvvs2DBAvr27Vt8YUVwcPAVv9fIkSP54YcfOHbsGP/73//o1asXTZo0ueJyleH2HrstW7YwevTo4vdFF0AMGzaMqVOnkpqaytGjR4s/r1WrFu+88w4vvPACI0aMIDIykkGDBvG73/2u8tVXMaN5b2xpO7BtWwDtBl5xfhEREW9ls9n4ZFxvrz8Um5GRwb59+3jhhRe46qqrAPjxxx+LP4+NjeWTTz7h1KlTxYdiS2rfvj2rV69mxIgRZa6/bt26xc9hBXPvYHZ29hXr+umnn7jhhhu4/fbbAfNCif3799OmTRsAWrZsSUhICGvWrKFZs2ZlriM2NpaEhATmzp3LF198wZ///Ocrbrey3A52PXv2ZMeOHZf8fOrUqRdNa9OmDbNmzXJ3Ux5ndPgF/PQutu2LYMjfwBFodUkiIiIVZrPZCAvy7sfCR0REEBkZyX/+8x/q1atHSkoK06ZNK/588ODB/Otf/2L8+PE88cQT1K9fn23btlG/fn26du3KhAkTGDNmDM2bN2fw4MEUFBSwfPlyfvOb3wDQq1cv5syZQ9euXXE6nbzyyisEBl753/cWLVrw5Zdf8tNPPxEREcGsWbNIS0srDnbBwcE8+OCD/PWvfyUwMJBu3bpx8uRJdu3aVXzOHZh77Z577jlCQ0O58cYbq/indzE9K7akFteQHxSFLTsD9i63uhoRERG/Z7fb+dvf/sbWrVsZMmQIU6ZMKXVKV1BQEO+88w7R0dH85je/YejQobz11lvF56H17NmT6dOns2zZMm6//Xbuu+++UhcaTJo0iUaNGnHPPffw1FNPcf/995frVLCHH36YDh068MADD3DvvfcSExNT6pYpAI888ghjx45lxowZ3HrrrTz++OOcPHmy1DyDBw8mICCAm2++uVyHbyvLZvjADW+cTiebNm2iS5cu1X5VbPrssdTf/1/oMgp+8Vq1bUsqx1N/JqRqqF++Q73yHSV7lZ+fz759+2jVqpXXnb9e0x0+fJgbb7yR2bNn071790seps7JyblkD935vdQeuwtkNL7eHNm+EAryLK1FREREfFN+fj6pqan8/e9/p3PnzsTHx3tkuwp2FzhXNwEjvCHknIY9y6wuR0RERHzQTz/9RN++fUlKSuLZZ5/12Ha9+4xKK9gcGB1uw7buLdg6H2JvsboiERER8TElLzY1DOOiJ01UF+2xK4PR4RfmyPbFkJ9jaS0iIiIi5aVgV5amV0OdJpB3FvZ8Y3U1IiIiIuWiYFcWmx2K9tpt+czSUkRERETKS8HuUhKGm687Pof8K9+hWkRERMRqCnaX0qQ7RDSH/EzY9ZXV1YiIiIhckYLdpdhs0PEX5vjW+ZaWIiIiIlIeCnaX03GY+brzS8jLtLYWERERP3Tvvffy4osvWl2G31Cwu5zGXSGqJeRnmeFORERExIsp2F2OzXZ+r91WXR0rIiIi3k3B7ko6Fl4du+tryD1rbS0iIiJ+7PTp00ycOJEePXrQuXNnfv3rX7N///7iz48cOcK4cePo0aMHXbp0YfDgwSxfvrx42SeffJJevXrRqVMnbrrpJubNm2fRN7GOHil2JQ0TIbotpO+GHV9Ap5FWVyQiIuKXfv/733PgwAHeeOMNwsPD+etf/8pvfvMbFi9eTGBgIM899xz5+fl88MEHhIWFsXv3bsLCwgCYPn06e/bs4d///jdRUVEcPHiQnJya9/QoBbsrKToc+/1fzcOxCnYiIuIrDMM8T9yTAsPMfzvdtH//fpYtW8ZHH31Et27dAHjllVe4/vrrWbp0KYMGDSIlJYWbb76Z2NhYAJo1a1a8fEpKCvHx8SQmJgLQtGnTKvgyvkfBrjw6DjeD3e6lkHMaQiKsrkhEROTyDAPeuRkOrfXsdpv1gvu/cDvc7dmzh4CAADp37lw8LSoqilatWrFnzx4ARo8ezbPPPsvKlSvp06cPN910E3FxcQDcfffdPPbYY2zbto1rrrmGgQMHFgfEmkTn2JVH/XiIiQVnHmxfYnU1IiIi5eT+njNvNnLkSJYuXcrtt9/Ozp07ueOOO5g9ezYA/fr149tvv2XMmDGcOHGCMWPG8NJLL1lcsedpj1152GzmI8a+m2LerLjL3VZXJCIicnk2m7nnzEcOxbZp04aCggJ+/vnn4j1tGRkZ7Nu3j7Zt2xbP16hRI+6++27uvvtupk2bxty5c7n33nsBqFu3LsOGDWPYsGF8/PHHvPzyy0yaNKlqvpePULArr47DzGC3ZxlkZ0BolNUViYiIXJ7NBkG1rK6iXFq2bMkNN9zAn//8ZyZPnkx4eDivvPIKDRo04IYbbgDgxRdf5LrrrqNly5acOXOGtWvX0qZNG8C8eKJjx460a9eOvLw8vvvuu+LPahIFu/KqFwv1O8KJrbB9MXQdZXVFIiIifmXKlCm8+OKLjBs3jvz8fK666ireeustAgMDAXC5XDz33HMcO3aM8PBwrr32Wv7whz8AEBgYyKuvvsqRI0cICQmhe/fuvPrqq1Z+HUso2Lmj4zAz2G35TMFORESkChSdIwcQERHByy+/fMl5//znP1/ys0ceeYRHHnmkSmvzRbp4wh1FT6HY+x1knbS0FBEREZELKdi5I6atecNiwwnJ/7O6GhEREZFSFOzcVfSIsa3zra1DRERE5AIKdu4qOhy773s4l2ptLSIiIiIlKNi5q24raNwVDBck/9fqakRERESKKdhVRNFeuy06HCsiIt7DMAyrS5AKqqreKdhVRFGwO/iDDseKiIjliu7zlpXl4adMSJUp6l1RLytK97GriMjm0KgzHP0ZdiyB7vdZXZGIiNRgDoeDyMhITpw4AUBYWBi2CjzWS6qHYRjk5uZit9sv6othGGRlZXHixAkiIyNxOByV2paCXUXFDzWD3fZFCnYiImK5hg0bAhSHO/EehmGQn59PYGDgJQN3ZGRkcQ8rQ8GuouKGwrIXzJsV55yBkDpWVyQiIjWYzWajUaNG1K9fn/z8fKvLkRKcTifbt2+nbdu2Ze6RCwwMrPSeuiIKdhVVLxai20H6Ltj1FSTeYXVFIiIiOByOKgsJUjWcTicAISEh1d4bXTxRUTabeTgWIHmhtbWIiIiIoGBXOfFDzNddX0N+jrW1iIiISI2nYFcZjbtBnSaQnwl7v7W6GhEREanhFOwqw2aDuMK9djocKyIiIhZTsKusovPsdiwBZ4G1tYiIiEiN5nawW79+PePGjaNv377ExsaydOnSci+7YcMGOnTowO233+7uZr1X894QWheyM+DAKqurERERkRrM7WCXlZVFbGwszzzzjFvLnTlzhkmTJtG7d293N+ndHAEQd6s5vn2RtbWIiIhIjeZ2sOvXrx+PP/44N954o1vLPfPMMwwZMoQuXbq4u0nvF3+b+Zq8CFwua2sRERGRGssj59jNmzePQ4cOMWHCBE9szvNa9YOgcDibAikbra5GREREaqhqf/LE/v37mTZtGnPmzCEgoHKbK7pzc3UpWr/b27EHYmt7I/Zt83Ft+y9Goy5VX5yUUuFeiSXUL9+hXvkO9cp3VLZX7ixXrcHO6XTy5JNP8uijj9KqVatKry8pKakKqqqe7USFJNCa+eT9PI+tdW8zb4Ui1c5TfyakaqhfvkO98h3qle/wRK+qNdhlZmayZcsWkpOTef755wFwuVwYhkGHDh14++233bqYIjExsVqfseZ0OklKSqrYduLbYPz8EiGZh+nSJATqx1dPkQJUslficeqX71CvfId65Tsq26ui5cujWoNdeHg4CxeWvnHvhx9+yJo1a5gxYwZNmzZ1a32eerBxhbYTFgmt+8OuL3HsXAKNEqqlNilND7v2LeqX71CvfId65Ts80Su3g11mZiYHDx4sfn/48GGSk5OJiIigcePGTJs2jePHj/Pyyy9jt9tp3759qeWjo6MJDg6+aLpfiB8Ku740n0LRb6LV1YiIiEgN43aw27JlC6NHjy5+P2XKFACGDRvG1KlTSU1N5ejRo1VXoS+JHQQ2OxzbDBn7Iaql1RWJiIhIDeJ2sOvZsyc7duy45OdTp0697PKPPvoojz76qLub9Q21YqDFNbB/BWxfDL3HW12RiIiI1CB6VmxVK3p2bPLCy88nIiIiUsUU7Kpa3GDz9eAaOHfC2lpERESkRlGwq2oRTaFxN8AwD8eKiIiIeIiCXXWIH2K+6nCsiIiIeJCCXXWIv8183fc9ZJ+ytBQRERGpORTsqkNMO4iJBVc+7PrK6mpERESkhlCwqy66OlZEREQ8TMGuuhQFu91LIT/b2lpERESkRlCwqy6NOkNEc8jPgj3LrK5GREREagAFu+pis+nqWBEREfEoBbvqFFcY7HZ8Ds58a2sRERERv6dgV52a94KwGMg5BftXWl2NiIiI+DkFu+pkd0Dcreb49kXW1iIiIiJ+T8GuuhUdjt35JRiGtbWIiIiIX1Owq24tr4WAEDh9CE5ss7oaERER8WMKdtUtKAxa9TPHd35hbS0iIiLi1xTsPKH9zebrTj1eTERERKqPgp0nFAW7w+sgM93aWkRERMRvKdh5QkRTaJAAhst8xJiIiIhINVCw85Tiw7E6z05ERESqh4Kdp7S/xXzd842eQiEiIiLVQsHOU5p0h7BoyDkNh9ZaXY2IiIj4IQU7T7E7oO2N5rgOx4qIiEg1ULDzpOLz7L60tg4RERHxSwp2ntRmANgDIG0nnNxrdTUiIiLiZxTsPCk0Epr3Nsd1s2IRERGpYgp2nlZ0dazOsxMREZEqpmDnaUXn2R1YBblnra1FRERE/IqCnadFt4W6rcGZB3u/s7oaERER8SMKdp5ms+lwrIiIiFQLBTsrFN/25CtwuaytRURERPyGgp0VmveBoNqQeQKObrK6GhEREfETCnZWCAiCNv3Ncd2sWERERKqIgp1VdJ6diIiIVDEFO6u0uxGwmYdizx6zuhoRERHxAwp2VgmvD026meO79BQKERERqTwFOysVH47VeXYiIiJSeQp2Viq67cmebyE/x9paRERExOcp2FmpYSeo3QjyM+HASqurERERER/ndrBbv34948aNo2/fvsTGxrJ06dLLzv/VV18xduxYevXqRbdu3bjrrrtYsWJFhQv2KzYbtLvJHN+p8+xERESkctwOdllZWcTGxvLMM8+Ua/7169fTp08f3nrrLT777DN69uzJww8/zLZt29wu1i+VvO2JYVhbi4iIiPi0AHcX6NevH/369Sv3/P/3f/9X6v0TTzzBN998w7Jly+jQoYO7m/c/rfuBIxhOHYDUHVA/zuqKRERExEd5/Bw7l8tFZmYmkZGRnt60dwqqBa2uM8d1s2IRERGpBLf32FXW22+/TVZWFoMGDXJ7WafTWQ0VXbz+6t7OhWxtb8S++2uMnV/i6v2oR7ftq6zqlVSM+uU71CvfoV75jsr2yp3lPBrsFi5cyGuvvcbrr79OdHS028snJSVVQ1XWbadIUH5TEgEOrSFp3fc4g+p4dPu+zNO9kspRv3yHeuU71Cvf4YleeSzYLV68mD/96U9Mnz6dPn36VGgdiYmJOByOKq7sPKfTSVJSUrVvpyzG5nhsqcl0CkvFSLjOo9v2RVb2StynfvkO9cp3qFe+o7K9Klq+PDwS7BYtWsQf//hHXn31Va6//voKr8fhcHjkD6+ntlNK7C2Qmox991fQ+U7PbtuHWdIrqTD1y3eoV75DvfIdnuiV2xdPZGZmkpycTHJyMgCHDx8mOTmZlJQUAKZNm8bEiROL51+4cCGTJk1i0qRJdO7cmdTUVFJTUzl79mwVfQU/0a7wKRS7l4KzwNpaRERExCe5vcduy5YtjB49uvj9lClTABg2bBhTp04lNTWVo0ePFn8+d+5cCgoKeO6553juueeKpxfNL4Wa9oDQKMjOgMProEXFDleLiIhIzeV2sOvZsyc7duy45OcXhrXZs2e7X1VN5AiAtjdC0lzY+aWCnYiIiLhNz4r1Ju0LD8fu/NLaOkRERMQnKdh5k7Y3gM0BqcmQccDqakRERMTHKNh5k9AoaN7bHN/1lbW1iIiIiM9RsPM27W8yX/V4MREREXGTgp23aX+L+brve8g9Z20tIiIi4lMU7LxNTHuIagnOPNi33OpqRERExIco2Hkbm+38XjsdjhURERE3KNh5o+LbnnwFhmFtLSIiIuIzFOy8UYtrILAWnDsGR3+2uhoRERHxEQp23iggGNr0N8d1s2IREREpJwU7b6Xz7ERERMRNCnbeql3h/exSfoKzx62tRURERHyCgp23qt0AGnczx/UUChERESkHBTtvpsOxIiIi4gYFO29W9HixPd9CQa61tYiIiIjXU7DzZg07Q3hDyM+EA6usrkZERES8nIKdN7Pbz++1021PRERE5AoU7Lxd0Xl2Oz7XUyhERETkshTsvF2rfuAIhlMHIG2n1dWIiIiIF1Ow83bB4dDqWnNcV8eKiIjIZSjY+YJ2N5uvOs9ORERELkPBzhcUXUBxcA1kZ1hbi4iIiHgtBTtfENUS6sWD4YTd31hdjYiIiHgpBTtf0V6HY0VEROTyFOx8RdFtT3Z/Dc4Ca2sRERERr6Rg5yua9oCQSPMcu8Prra5GREREvJCCna9wBEC7G81x3fZEREREyqBg50uKDsfu+sraOkRERMQrKdj5kjYDwOaAE9sg44DV1YiIiIiXUbDzJWF1oXkvc1x77UREROQCCna+pvi2JzrPTkREREpTsPM1RY8X2/c95J6zthYRERHxKgp2vqZeLES2AGce7FtudTUiIiLiRRTsfI3Ndv7qWD2FQkREREpQsPNFJR8v5nJZW4uIiIh4DQU7X9SyLwSFw7ljcHSj1dWIiIiIl1Cw80UBwdB2oDmevMjaWkRERMRrKNj5qvih5ut2BTsRERExKdj5qnY3gj0Q0nZC6k6rqxEREREv4HawW79+PePGjaNv377ExsaydOnSKy6zdu1ahg0bRkJCAjfeeCOfffZZhYqVEkIioNV15rj22omIiAgVCHZZWVnExsbyzDPPlGv+Q4cO8dBDD9GzZ0/++9//ct999/GnP/2JFStWuF2sXCB+iPmqYCciIiJAgLsL9OvXj379+pV7/o8//pimTZvy+9//HoA2bdqwYcMG3n33Xa699lp3Ny8lxQ6GRU/AkQ1wJgXqNLa6IhEREbFQtZ9jt2nTJnr37l1qWt++fdm0aVN1b9r/1W4Aza42x7cvtrYWERERsZzbe+zclZaWRkxMTKlpMTExnDt3jpycHEJCQsq9LqfTWdXllbn+6t5OVbK1H4T90FqM5IW4ut9vdTke44u9qsnUL9+hXvkO9cp3VLZX7ixX7cGuKiUlJfnVdqpCsNGGBID9K0latwJnUG2rS/IoX+qVqF++RL3yHeqV7/BEr6o92MXExJCWllZqWlpaGuHh4W7trQNITEzE4XBUZXmlOJ1OkpKSqn07VasLRlI8ttRkOoWkYHS6y+qCPMI3e1VzeUu/DMPA6TKHgjJfXRS4DFwuA6cBLsMcdxngdBnm8ob53pxeOF/hOozC9yXnNccpXM7AcBWu1zDrcRVtxzDnK/6ssF7DAAMDl6uMaQbFyxR9v6JlXeZMpeYzMLdfvJ7C+QpnBQNchouTJzOIiorCZrOd/9ld4udZ8jPDuPRnF7Jd+N5WekrJ5YvWa2CUGL945UaJCcalNlxqmyXruaAi28V1Xnb+S9RxpXrKUealt2MYnD51mojIiIt+flfa0IU1uvvzuriW0pspfl9ixcZFI2X3rDI/k6pyhZ9mMYfdxn19WtC7dfRl56vs34FFy5dHtQe7Ll268P3335ea9sMPP9ClSxe31+VwODzyj4KntlNl4odCajL2HYuh66+srsajfK5XNVxRv3ILnGTlOjmXW0BmXgGZuU4ycwvIKhzPLXCRV2C+moOT3HxX4fTC9wXn3+c5C19LjOeXmJbrdBUHOimn/dlWVyDldTjH6gpqtNCgAPq2q1+ueT3xb5bbwS4zM5ODBw8Wvz98+DDJyclERETQuHFjpk2bxvHjx3n55ZcB+OUvf8mcOXN4+eWXGTFiBGvWrOHzzz/nzTffrLpvUdPFD4HvX4bd30BeFgSFWV2R+JECp4uzOQWcycnnTHbRaz5ncvLJzHWSne8kJ99Jdp6TrHwnOXnmtOzCaTn5TrLynGScyyJ/0Tdk5RWQ7/SugGW3QYDdjsNuKx7sNrDbbNgLxx02GzZb6c9sNgrfl1yucP4LpttsNhzFy5VcP4XvzWk2zs9jK/WesqdRcnrhOmylp7mzjGG4OHb0KI0bN8Zmu/L1dUV7cWylxm2l925dYm/cpRgGZS5vK35fcpu2EvOVWKasiSU3QOk9Q2XtbbxwngvnK/q8rL07ZW22vHuBystlGBw5fJgmTZtiv9IeOyr4sypyiZ6V+v6X7NMVtlvmZ5eopap/iGV8rbL2uF6Kw26nf2y9Kiyo8twOdlu2bGH06NHF76dMmQLAsGHDmDp1KqmpqRw9erT482bNmvHmm28yZcoU3n//fRo2bMgLL7ygW51UpYadIKI5nD4Ie7+FuMFWVyReLCffSdq5XFLPFg4lx8/mcjIzr0SQyyczrypPzHaVehcSaKdWUAC1ggMIC3IQHhxAaJCDkEAHwQF2ggMcBAXYzfFA831w0fsAO0FFg8NRYtxOUICt1LRAh40ghxncAux2HA4bAUUhrjC8icnpdLJp01m6dGmtveFezuxVBl26tFCvpJjbwa5nz57s2LHjkp9PnTq1zGUWLFjg7qakvGw2M8ytfQOSFynY1VDZeU6On8kxh7O5nCgaP5PLibM5xcHtTE5BhdYfFuSgTkggdUIDqBMSSO2QAMJDAgkNtBMa6CAkyEFYYAChQeb70KCAwlc7QQ4bR/bvpWtiPLVDg8wgF+ggwKGnGoqIVCWfuipWLiN+iBnsdn4OzgJwqLX+xOUyOHE2l0MZWRxMz+LgySwOZWQVB7fjZ3I460ZgC3LYqVc7mJjawdQLD6Ze7fNDdK0gIkIDS4W48JAAAisRwpxOJ5vOHKJNvXDtWRARqUb6199fNOsFYdGQlQ4HVkHr8j8dRLxDXoGLfWmZ7EvL5FBhcDt40hwOZ2STV+C64jpCAx00jAihfu1gGtQJoUGdYOrXDqF+4Wu92kHUCw+hTmjAla+iExERn6Ng5y8cAdB+EGz6wHwKhYKd1ypwujhwMotdx8+y49g5dp44y85jZ9mXlknBZa7adNhtNI4MoXndMJpFhdGsbhiNI0NoUDuE+oUhLjxYgU1EpCZTsPMn8UPOB7tBL13+CifxiBNnc9iacoZtKWfMIHf8HHtSz11y71vt4ABa16tF8+haNIsKNUNc3TCa1w2jUUSIzkkTEZHLUrDzJ637Q2AtOHMYUjZCk25WV1RjGIbBkVPZbDlyhm0pp9mScoYtR05z4mxumfOHBNpp36A27erXJrZhOO0b1KZ9g9o0igjRHjcREakwBTt/EhgC7QbCtv/C9kUKdtXoxNkc1u49yZYjp9macoYtKac5lZV/0Xw2G7SOqUXHxhHENjTDW2yD2jSNCtUtNkREpMop2PmbuKGFwW4x3PC01dX4jczcAtbtO8nK3Wms2p3G9mNnL5onwG6jfYPaJDSpQ8fGESQ0qUNcwzrUCtavmYiIeIb+xfE37W4EewCkboe03RDT1uqKfFKB08XmI6dZuSuNlbvT2Hgw46KnJXRsXIeuzSNJaBxBx8YRtG8YTnCAbuUhIiLWUbDzN6GR0Oo62LMMti+Evo9bXZHPSDmVzTfbT7BiZyqr96ZfdF+4JpGhXNsuhr7tYujTJoa6tYIsqlRERKRsCnb+KG6IGeySFynYXYZhGGw7eoal207wdfIxthw5U+rzOiEBXNM2hmvaxtC3bQwtosN0YYOIiHg1BTt/FDcYFj8BR36EMylQp7HVFXmNfKeLtXtPsjT5OF9vO86RU9nFn9ls0K15FAPi6tO3bQwJTSJw6AIHERHxIQp2/qh2Q2jaAw6vhx1LoMevra7IUmdz8vluRypfbzvOtztOlDrEGhJo59p29bgxvgED4usTEx5sYaUiIiKVo2Dnr+KGmMEueVGNDHZOl8HK3WnM23CYL7ceI7fEDYFjwoO4Ia4BAzs0oG/bGEKDdMGDiIj4BwU7fxU/FJY+A/tXQHYGhEZZXZFH7Dh2lnk/HWbBxiOlbg7cOqYWN3VsyI0d6tOlWZQOsYqIiF9SsPNX0W2gXjykJsPOr6DzXVZXVG1Sz+byv59T+Oynw2xNOX8BRFRYILd1bsyI7k1JbBKhCx9ERMTvKdj5s/ghZrDbvsjvgl1ugYsfDuXw2uYNLN+VhtNl3mMu0GFjQFx9RnRryvWx9QkK0LNVRUSk5lCw82dxg+H7v8LupZCfDYGhVldUaScz85iz5gDvrz5A6rnzh1o7N4vkjm5NGNKpMVG6v5yIiNRQCnb+rFEXiGgGpw/Bnm8h7larK6qw3SfO8c6qfczbcLj4QoioEDu/7NmSEd2b0bZ+uMUVioiIWE/Bzp/ZbOZeu7X/Mg/H+liwMwyDH/akM3PFXr7dkVo8PaFJHe7v05LGruP06NYeh0NXtYqIiICCnf+LH3o+2BX8DQK8/z5tuQVO/rcphbdX7mP7sbOAmVEHxjfg131bcXWrurhcLjZtOmFxpSIiIt5Fwc7fNe8NtRvB2aOw+xuv3mt3Ojuf93/Yz3urD5BWeP5caKCDO69qythrWtEyppbFFYqIiHg3BTt/Z3dAx+Gw5jXY8qlXBrvT2fm8s3If76zaV/xUiIZ1QhhzTUvu7tGciLBAiysUERHxDQp2NUHiCDPYbV8Cuecg2DsuNDiTk8+slft5e+VezhQGutgGtXmkfxtuTWxEoEO3KhEREXGHgl1N0Lgb1G0NJ/fCjs+h00hLyzmbk8+sVfuZueJ8oGvfIJzf3tCeQQkNseupECIiIhWiYFcT2GyQcAd8/7J5ONaiYHc2J593V+1n5sp9nM7OB6Bd/XB+O7AdtyY0UqATERGpJAW7miKxMNjtXgpZJyGsrsc2fS63gPd+2M+/V+zlVJYZ6NrUq8VvB7ZncGIjPbdVRESkiijY1RT1YqFBIhxPgm3/havGVvsmDcNg0eajTF64lbRzeQC0rleL397QjiGdGivQiYiIVDEFu5ok8Q4z2G2ZV+3B7ujpbP68YAtLk817zbWKqcVjN7Tlts5NFOhERESqiYJdTZIwApY+A/tXwpkUqNO4yjfhchl8tP4gU5ds52xuAYEOG49c35ZH+rchOEBPiBAREalOCnY1SWQzaNYLDq2BLZ9BnwlVuvq9qef4w2dJrN13EoAuzSJ5+Y5OtG9Qu0q3IyIiImVTsKtpEu8oDHafVlmwK3C6+PeKffxt6U7yClyEBjp46uZYxvRpqcOuIiIiHqRgV9N0HAafT4KUjZC+B6LbVGp1W46cZtK8zWxNOQPAte1i+MuwRJrVDauKakVERMQNurV/TVMrBlpfb44nfVrh1eTkO3npi+3c/toqtqacISI0kFdGdub9+69WqBMREbGIgl1NlFh4g+Itn4JhuL34oZNZ/OK1Vbzx3R6cLoPBiY1Y+kQ/7ujeFJtNh15FRESsokOxNVHcYAgIgbSdcCwJGnUq96Kr96TzyJwNZGTlExMezF+GJXBTx4bVWKyIiIiUl/bY1UQhdaDdTeZ40iflWsQwDGav3s+9b68lIyufTk0jWPjoNQp1IiIiXkTBrqZKvMN83fIZuFyXnTWvwMUf52/hz//dSoHL4BddGjP3od40igj1QKEiIiJSXjoUW1O1uwmC68CZw3BoLbToXeZsaedyeeSDn1i3/yQ2G0y6JY6Hrmutc+lERES8kPbY1VSBoRA3xBy/xOHYrSmnuf2fq1i3/yS1gwN4574ejOvXRqFORETES1Uo2M2ZM4cBAwaQmJjIyJEj2bx582Xnf/fdd7n55pvp1KkT/fr14y9/+Qu5ubkVKliqUOII83XbAnDml/po0eYURrzxA0dOZdM6phbzx19D/7j6nq9RREREys3tYLdkyRKmTJnC+PHjmT9/PnFxcTzwwAOkp6eXOf/ChQuZNm0aEyZMYMmSJbz44ossWbKEV199tdLFSyW1uh7CYiArHfYuB8xnvb7y5Q4mfLiRnHwX/drXY/74a2hbP9zSUkVEROTK3A52s2bN4s4772TEiBG0bduWyZMnExISwrx588qcf+PGjXTr1o2hQ4fStGlT+vbty5AhQ664l088wBFgPokCIOkTzuUW8NAHG/jnt7sB+M11rXlnTA8iQgMtLFJERETKy61gl5eXx9atW+nTp8/5Fdjt9OnTh40bN5a5TNeuXdm6dWtxkDt06BDLly+nX79+lShbqkzh1bHG9kU8/O5Kvt52nKAAO6/e2Zk/3hqvZ72KiIj4ELeuis3IyMDpdBIdHV1qenR0NHv37i1zmaFDh5KRkcGvfvUrDMOgoKCAX/7yl4wbN87tYp1Op9vLVGT91b0dr9K4O/aIZthOHyL8wDLCg/vw7pgedG0e6dU/hxrZKx+mfvkO9cp3qFe+o7K9cme5ar/dydq1a3nzzTd55pln6NSpEwcPHuTFF1/ktddeY/z48W6tKykpqZqqtGY73iLd1YObOMTtjh+4uuct2E7uZ9NJq6sqn5rWK1+nfvkO9cp3qFe+wxO9civYRUVF4XA4LrpQIj09nZiYmDKXmT59OrfddhsjR5rPJ42NjSUrK4unn36ahx9+GLu9/EeDExMTcTgc7pTsFqfTSVJSUrVvx5vMXLmPBWk9uCn4M24M/Bn6xZtPpvByNbFXvkz98h3qle9Qr3xHZXtVtHx5uBXsgoKC6NixI6tXr2bgwIEAuFwuVq9ezahRo8pcJicn56LwVvSlDDcfQO9wODzyh9dT27HafzcdYcrnO4DmnKzVmrqZe2HnEuh6j9WllVtN6ZW/UL98h3rlO9Qr3+GJXrl9VezYsWOZO3cu8+fPZ8+ePTz77LNkZ2czfPhwACZOnMi0adOK5+/fvz8fffQRixcv5tChQ6xatYrp06fTv39//UG00KrdaTz1yc8AjL2mFVFX321+sOVTC6sSERGRynD7HLtbb72VkydPMmPGDFJTU4mPj2fmzJnFh2KPHj1aag/dww8/jM1m4+9//zvHjx+nbt269O/fn8cff7zqvoW4ZVvKGR6avYF8p8HgTo348+AO2DJC4NsXYe93cO4EhOtmxCIiIr6mQhdPjBo16pKHXmfPnl16AwEBTJgwgQkTJlRkU1LFDp3MYsysdZzLLaBnq7pMG9kZu90G0W2gcTdI+Qm2zoeeD1ldqoiIiLhJz4qtQTIy87hv1jpOnM0ltkFt3hp9FSGBJQ6Hd/6l+frTbHDz/EcRERGxnoJdDZGT7+TX7//I3tRMGkWE8O79ZTxRInEkOILheJK5505ERER8ioJdDVDgdPHoRxvZcCCDOiEBvHf/1TSKCL14xrC60OF2c3zDux6tUURERCpPwc7PGYbBM//bWvyosJn39aB9g9qXXqD7GPM1aR7knvVIjSIiIlI1FOz83CcbDjNn7UFsNph+VxeublX38gu06APR7SA/E7bM80yRIiIiUiUU7PzY4Ywsnlu4DYCnboplUGKjKy9ks0G30eb4hveqsToRERGpagp2fsrlMpj46WbO5RbQvUUU4/q1Kf/CXX4F9kDzAoqjm6uvSBEREalSCnZ+6oO1B/hhTzqhgQ6mjeyMw24r/8K1YiB+iDn+k/baiYiI+AoFOz+0Ly2TKUu2A/D7QXG0jKnl/kq63We+bv4E8rKqsDoRERGpLgp2fsbpMnjqk5/JznfSp0009/ZqUbEVteoHkS0g9zRsW1ClNYqIiEj1ULDzMzNX7GXDgQzCgwN4+Y5O5uPCKsJuL3ERxbtVVp+IiIhUHwU7P7Lz+FmmfbUTgKeHdKBpVFjlVth1FNgccGgtnEiuggpFRESkOinY+Yl8p4sn5m4iz+liQFx9Rl7VtPIrrd0QYgeZ4z+9X/n1iYiISLVSsPMTr3+7hy1HzhARGsjU4YnYbBU8BHuhoosofv4I8nOqZp0iIiJSLRTs/MCWI6f5x7JdADz/iwTq1wmpupW3vQHqNIXsDEheWHXrFRERkSqnYOfjcgucPDF3EwUug8GJjRjaqRxPl3CH3QHd7jXHdU87ERERr6Zg5+P+9vUudh4/R0x4EM//IqHqDsGW1HUU2OywfwWk7a769YuIiEiVULDzYRsOnOSt7/cAMGV4J+rWCqqeDUU0hbYDzXHttRMREfFaCnY+KiuvgCfn/ozLgBHdmnJjhwbVu8Giiyg2fQgFedW7LREREakQBTsf9fIXO9ifnkWjiBCeHtqh+jfY/mYIbwhZabBjSfVvT0RERNymYOeDdhw7y3ur9wPw0ohORIQGVv9GHYHQ9R5zXIdjRUREvJKCnQ/629c7MQwYlNCQ69rX89yGuxZeHbtnGWTs99x2RUREpFwU7HxM0uHTfLH1GDYbPHFje89uvG4raH29Of7TbM9uW0RERK5Iwc7HTPt6BwDDujShXYPani+g+xjzddMccBZ4fvsiIiJySQp2PuTH/Sf5bkcqAXYbvx3YzpoiYgdDWAycPQq7vrKmBhERESmTgp2PMAyDv35p7q0beVUzWkTXsqaQgCDocrc5vuFda2oQERGRMinY+YhVu9NZu+8kQQ47jw5oa20xRfe02/01nD5sbS0iIiJSTMHOBxiGwV+/MvfW3dOrOY0jQ60tKKYdtLwWDBes/Ze1tYiIiEgxBTsf8E3yCX4+dIrQQAePXG/x3roivSeYrz++CzmnLS1FRERETAp2Xs7lMnilcG/dmGtaUq92sMUVFWp3E8TEQt5ZnWsnIiLiJRTsvNySLUfZfuwstYMDeOi61laXc57dDn0eNcfX/EvPjxUREfECCnZerMDp4tWvdwLw62tbExkWZHFFF+h0p/n82LMpsGWe1dWIiIjUeAp2Xmz+xiPsTc0kKiyQ+/u2tLqciwUEQ8+HzPEf/gGGYW09IiIiNZyCnZfKK3Ax/ZtdAIzr14baIYEWV3QJV90PQeFwYivs/sbqakRERGo0BTsv9Z8fD3E4I5t6tYMZ3bul1eVcWmjk+fva/TDd0lJERERqOgU7L5ST7+Sfy8y9dRP6tyU0yGFxRVfQaxzYHLDve0jZZHU1IiIiNZaCnRf6YM0Bjp/JpUlkKL+8upnV5VxZZHNIGG6O//APa2sRERGpwRTsvExmbgGvf7cHgMduaEtwgJfvrSvS5zHzdet8OHXQ2lpERERqKAU7LzNr1T5OZubRMjqMEd2aWl1O+TXqBK2vB8MJq1+3uhoREZEaqULBbs6cOQwYMIDExERGjhzJ5s2bLzv/mTNnmDx5Mn379iUhIYGbb76Z5cuXV6hgf3Y6K583v98LwOM3tifA4WO5u2iv3U/vQ3aGtbWIiIjUQG4nhyVLljBlyhTGjx/P/PnziYuL44EHHiA9Pb3M+fPy8hg7dixHjhxh+vTpfPHFFzz//PM0aNCg0sX7m5kr93I2p4DYBrUZ2qmx1eW4r80AaJAI+Zmw/m2rqxEREalx3A52s2bN4s4772TEiBG0bduWyZMnExISwrx5ZT95YN68eZw+fZrXXnuN7t2707RpU66++mri4uIqXbw/yc5z8v7qAwD8bmA77HabxRVVgM12/jFja9+E/Bxr6xEREalh3Ap2eXl5bN26lT59+pxfgd1Onz592LhxY5nLLFu2jC5duvDcc8/Rp08fhgwZwr/+9S+cTmflKvczCzYd4XR2Ps3qhnJTx4ZWl1NxCcOhThPIPAGb/2N1NSIiIjVKgDszZ2Rk4HQ6iY6OLjU9OjqavXv3lrnMoUOHWLNmDUOHDuWtt97i4MGDTJ48mYKCAiZMmOBWsdUdBovW7+nQaRgG767aB8Cons3BcOG7udeO7eqHsC99GuOHf+Dq/CuwVf25glb1SipG/fId6pXvUK98R2V75c5ybgW7ijAMg+joaJ5//nkcDgcJCQkcP36ct99+2+1gl5SUVE1VWrOdIltO5LLj+DmCHTbigjLYtOm0R7df1ewBXekUUAtH+i72ffkvTjfsc+WFKsjTvZLKUb98h3rlO9Qr3+GJXrkV7KKionA4HBddKJGenk5MTEyZy9SrV4+AgAAcjvP3Y2vdujWpqank5eURFBRU7u0nJiaWWk9VczqdJCUlVft2LvTmHPMw9ojuTel7dUePbbc62U4/AKtn0Ob4Yly3PFLl67eqV1Ix6pfvUK98h3rlOyrbq6Lly8OtYBcUFETHjh1ZvXo1AwcOBMDlcrF69WpGjRpV5jLdunVj0aJFuFwu7HbzkNz+/fupV6+eW6EOwOFweOQPr6e2A3A4I4ulyccBGHNNK//55ez9CKx9A9vB1TiOboSmV1XLZjzZK6k89ct3qFe+Q73yHZ7oldsnP40dO5a5c+cyf/589uzZw7PPPkt2djbDh5uPlJo4cSLTpk0rnv/uu+/m1KlTvPjii+zbt4/vvvuON998k3vuuafqvoUPm73mAC4DrmkbTfsGta0up+rUaQSd7jTHV023thYREZEawu1z7G699VZOnjzJjBkzSE1NJT4+npkzZxYfij169GjxnjmARo0a8fbbbzNlyhRuu+02GjRowOjRo3nwwQer7lv4qOw8J/9ZfwiA+3q3tLaY6tDnUdg0B5IXQvoeiG5jdUUiIiJ+rUIXT4waNeqSh15nz5590bSuXbsyd+7cimzKr/130xFOZeXTNCqUG+L98IbN9eOh7Y2w+2tY8zoMnnblZURERKTCfOyZVf7DMAze/WE/AKN7t8DhizckLo9rCh8ztvEDOH3E2lpERET8nIKdRdbuO8n2Y2cJDXRw11XNrS6n+rS8Fpr3hoIcWP6S1dWIiIj4NQU7i7y7aj8Aw7o1ISIs0NpiqpPNBgOfNcc3fgBpuywtR0RExJ8p2FngyKlsvtp2DPDTiyYu1LwXtB8EhhO+ec7qakRERPyWgp0FZq82b3HSp000sQ396BYnl3PD04ANkv8HhzdYXY2IiIhfUrDzsJx8Jx+vPwjAfX1aWluMJzXoAJ3vNseXPgOGYW09IiIifkjBzsOKbnHSJDKUgf54i5PL6f8HcATB/hWwZ5nV1YiIiPgdBTsPMgyDWYUXTdzXx49vcXIpkc2hx6/N8aXPgstlaTkiIiL+RsHOg9YV3uIkJNDOnVc1s7oca1z7FATVhmObYetnVlcjIiLiVxTsPKjohsTDujYlMizI2mKsUiv6/E2Ll70Aznxr6xEREfEjCnYeYt7i5DhgHoat0Xo9ArXqQcY++Ok9q6sRERHxGwp2HvLBmgM4XQa9W0cT17CO1eVYKzgcrptoji9/GfIyra1HRETETyjYeUBOvpOP1pm3OBlzTUtri/EW3cdAVEs4dxzWvGF1NSIiIn5Bwc4D/rcppebe4uRSAoKg/5/M8VXTIeuktfWIiIj4AQW7amYYBrMKL5oY3bsG3uLkchJGQINEyD0DK6ZZXY2IiIjPU7CrZuv3Z5B89AwhgXbu6lFDb3FyKXY7DHzGHF/3bzh1yNp6REREfJyCXTWbveYAAL/o0qTm3uLkctoOhBZ9wZkLy6daXY2IiIhPU7CrRmnncvliy1EARvWq4bc4uRSbDQY+a45v+hBObLe0HBEREV+mYFeNPt1wmHynQaemESQ0ibC6HO/VrAfEDQHDBcuet7oaERERn6VgV01cLqP4Fif39GxucTU+4IanwWaH7Yvg0DqrqxEREfFJCnbV5Ic96RxIz6J2cABDOze2uhzvVy8WuvzKHP/iD+ByWVuPiIiID1KwqyZz1poXTQzr1oSwoACLq/ER/f8PgmrDkR/hx7etrkZERMTnKNhVgxNnc/i68Lmwv9Jh2PKr09g8JAuwdDKcSbG2HhERER+jYFcNPvnxMAUug27NI/VcWHf1eACaXAV5Z+HziVZXIyIi4lMU7KqY02Xw4dqiiyZ0ixO32R0wdDrYAyB5IWxfbHVFIiIiPkPBrop9vyuVI6eyiQgNZHCnRlaX45saJkDvCeb4kv8HuWetrUdERMRHKNhVsaK9dSO6NSUk0GFxNT6s3ySIbAFnjsCyF6yuRkRExCco2FWho6ez+Sa56KIJPRe2UoLCYMjfzPG1b8LhDdbWIyIi4gMU7KrQf9YfwmXA1a3q0rZ+bavL8X1tb4DEOwEDFv4WnPlWVyQiIuLVFOyqSIHTxX/WHwL0pIkqdfNfIDQKjifBmtetrkZERMSrKdhVkW93pHL0dA51awVxS0JDq8vxH+H14KbCc+y+nQIZ+y0tR0RExJsp2FWRDwufNDGye1OCA3TRRJXqcg+0vBYKsmHRE2AYVlckIiLilRTsqsDhjCy+25kKwN1X6zBslbPZzAspHEGw5xvYMs/qikRERLySgl0V+HjdIQwDrmkbTcuYWlaX459i2sF1/88c/+L3kJ1hbT0iIiJeSMGukvKdLv7zY9FFE3rSRLW65ncQEwuZqdiWPmN1NSIiIl5Hwa6Svkk+TurZXGLCg7mxQwOry/FvAUHm48YA+6YPCE//2eKCREREvIuCXSXNKXzSxF09mhLo0I+z2rXoDd3HmKM/vwoFudbWIyIi4kWURCrhQHomK3alYbPBL3voogmPGfgsRq36hGQewvatHjcmIiJSRMGuEj5aZ55bd127ejSrG2ZxNTVIaBSuwa8CYF/zGuz4wuKCREREvEOFgt2cOXMYMGAAiYmJjBw5ks2bN5drucWLFxMbG8sjjzxSkc16lbwCF5/8qCdNWCb2Vo63Gm6OLxgHpw9bW4+IiIgXcDvYLVmyhClTpjB+/Hjmz59PXFwcDzzwAOnp6Zdd7vDhw7z00ktcddVVFS7Wm3y59RjpmXk0rBPCgLj6VpdTIx2J/w1Goy7mrU8+vV/PkhURkRrP7WA3a9Ys7rzzTkaMGEHbtm2ZPHkyISEhzJt36ZvGOp1OnnrqKR599FGaNWtWqYK9xYfFF000I0AXTVjCcAThGvEOBNeBQ2thmc63ExGRmi3AnZnz8vLYunUrDz30UPE0u91Onz592Lhx4yWXe+2114iOjmbkyJFs2LChwsU6nc4KL+vO+q+0nQPpWazem47dBiO7N6n2uuRixb2q0wyGTMcxbyys+jvOZr2h3Y0WVycXKu/vllhPvfId6pXvqGyv3FnOrWCXkZGB0+kkOjq61PTo6Gj27t1b5jI//vgjn376KQsWLHBnU2VKSkqq9DqqYjvzt58DILF+EMf3bee4J4qSMpm9akGzlrdTf/9/MeY9yLZ+/yY/tJ7VpUkZPPU7LJWnXvkO9cp3eKJXbgU7d507d46JEyfy/PPPU7du3UqvLzExEYfDUQWVlc3pdJKUlHTF7Ty3ejUAI3u1o0sX/zi07Gsu6lXCGxiz9hFwbDOJO/6Ga/T/wF6tf7zFDeX93RLrqVe+Q73yHZXtVdHy5eHWv3xRUVE4HI6LLpRIT08nJibmovkPHTrEkSNHePjhh4unuVwuADp06MAXX3xB8+blv6LU4XB45A/v5baTciqbnw+fxmaDmxMa6ZfJYsW9ctSCke/Cm/2wHVqD4/uX4IanrS5PLuCp32GpPPXKd6hXvsMTvXLrrP+goCA6duzI6sI9VmAGtdWrV9O1a9eL5m/dujULFy5kwYIFxcOAAQPo2bMnCxYsoGHDhpX/Bh721dZjAPRoUZd6tYMtrkZKiW4Dt80wx1dMg91Lra1HRETEw9w+VjV27FgmTZpEQkICnTp14r333iM7O5vhw817ik2cOJEGDRrw5JNPEhwcTPv27UstX6dOHYCLpvuKLwqD3c0JvhdKa4SE4bB/Bfz4Dnz2EIxbCXUaWV2ViIiIR7gd7G699VZOnjzJjBkzSE1NJT4+npkzZxYfij169Ch2u3/e/iP9XC7r9p0E4OaODSyuRi7p5ilwaD0cT4J5v4bR/wWHzrcTERH/V6F/7UaNGsWoUaPK/Gz27NmXXXbq1KkV2aRX+HrbcVwGJDaJoGmUHiHmtQJD4M734M3r4MBKWD4VBvzJ6qpERESqnX/uWqsmRYdhb9FhWO8X3QaGTjfHv38F9nxrbT0iIiIeoGBXTmdy8lm1Ow1QsPMZiXdAt/sAAz57EE4dtLoiERGRaqVgV07fbj9BvtOgXf1w2tQLt7ocKa9BL0GDRMhMhQ9GQNZJqysSERGpNgp25fTFFh2G9UmBofCr/0CdJpC2Ez7+FeTnWF2ViIhItVCwK4fsPCff7UgF4OaOCnY+J6IJ3PMpBEfAwdXmYVmXnq0oIiL+R8GuHJbvTCU730nTqFA6Nq5jdTlSEQ06wC/ngCMIkv8HX/wBDMPqqkRERKqUgl05fFl4NeyghIbYbDaLq5EKa3UtDPuXOb7uTfhhhrX1iIiIVDEFuyvIK3CxNPk4oPPr/ELCCLjpRXP866dh8yfW1iMiIlKFFOyuYPXedM7mFFCvdjBdm0VZXY5UhT4ToNcj5viCh2HvcmvrERERqSIKdlfwxZajgPkIMbtdh2H9xk0vQodfgCsf/jMKjm2xuiIREZFKU7C7DKfL4KuthYdhO+pB8n7Fbodhb0KLayD3DMwZCacPW12ViIhIpSjYXcaP+0+SnplHZFggPVvXtbocqWqBIeaVsvXi4GwKfHAHZJ+yuioREZEKU7C7jKJnww6Mb0CgQz8qvxQaZd7jrnYjSE2Gj+/RDYxFRMRnKa1cgmEYfFn0tAndlNi/RTYrvIFxHTiwEj77NRTkWV2ViIiI2xTsLiHpyGlSTucQFuSgb7sYq8uR6tYwAe76AOyBkLzQvKAiP9vqqkRERNyiYHcJnxfuresfV5+QQIfF1YhHtO4Hd38MASGw60vzgorcc1ZXJSIiUm4KdmUwDIMvdBi2Zmo3EEbNg6Bw2L8CZg/TBRUiIuIzFOzKsOvEOfalZRIUYKd/XH2ryxFPa9kXRv8PQiLh8Dp4bwhkplldlYiIyBUp2JXhy8J7113XLobw4ACLqxFLNO0OYxZDrXpwLAlmDYIzKVZXJSIiclkKdmX4apsZ7G7WYdiarWECjP0c6jSBtJ3wzi2Qsd/qqkRERC5Jwe4Cx84VsO3oWRx2GwPjG1hdjlgtpp0Z7qJawakD8M4gSN1pdVUiIiJlUrC7wNojuQD0al2XqFpBFlcjXiGqhRnuip5QMWuQeXhWRETEyyjYXWDtEfOpA7oaVkqp0wjGLIGGnSArDd4dDIfWW12ViIhIKQp2JRw/k8OO9HxsNp1fJ2WoFQ33LYRmPSHnNLx/O+xZZnVVIiIixRTsSvh62wkAujaLpH6dEIurEa8UGgn3zodW/SA/Ez4YAT/8AwzD6spEREQU7Er6svhqWF00IZcRVAt+NRc6/woMF3z1J/jsQcjLsroyERGp4RTsSsjJdxLssDFIh2HlSgJD4Bevw6CXweaApE/gnZvg1EGrKxMRkRpMwa6EmaO7M+OWGJpEhVpdivgCmw16PgSj/wth0eaVsm9dD/u+t7oyERGpoRTsSogIDSQmzGF1GeJrWl0Lv1kOjTpDVjq8/wtY84bOuxMREY9TsBOpCpHN4P4vodNdYDjhi9/DgochP9vqykREpAZRsBOpKoGhMOxNuPkv5nl3P39k3sz49GGrKxMRkRpCwU6kKtls0Hs83PsZhNaFlI3meXf7V1ldmYiI1AAKdiLVofX18JvvoEEiZKbC+7fB8pfBWWB1ZSIi4scU7ESqS1QLeOArSLgDXAXw7Yvw9o2QusPqykRExE8p2IlUp6AwGDEThv8bQiIg5Sf417Xwwz/B5bK6OhER8TMKdiLVzWaDTnfCI2ug7UBw5sJX/wfvDYGT+6yuTkRE/IiCnYin1GkM93wKQ/4OgbXgwCp44xr48R3d805ERKqEgp2IJ9lscNVYeHgVtLgG8jNh0ePwwQg4k2J1dSIi4uMU7ESsULcV3LcIbp4CASGw5xt4vRf8/B/tvRMRkQqrULCbM2cOAwYMIDExkZEjR7J58+ZLzjt37lx+9atf0aNHD3r06MGYMWMuO79IjWG3Q+9H4KEV0KQ75JyG+b+Bj++BjP1WVyciIj7I7WC3ZMkSpkyZwvjx45k/fz5xcXE88MADpKenlzn/2rVrGTx4MO+//z4ff/wxjRo14v777+f48eOVLl7EL9RrD/d/BQP+BPZA2LEY/nk1fPM85GVaXZ2IiPgQt4PdrFmzuPPOOxkxYgRt27Zl8uTJhISEMG/evDLnnzZtGvfccw/x8fG0adOGF154AZfLxerVqytdvIjfcATAdf8PHvoeWl1nXjm74hX4x1Wwea4Oz4qISLkEuDNzXl4eW7du5aGHHiqeZrfb6dOnDxs3bizXOrKzsykoKCAiIsK9SgGn0+n2MhVZf3VvRyrPb3sVEwv3zIcdi7F//Wdspw7AZw9irHsL181ToHE3qyusEL/tlx9Sr3yHeuU7Ktsrd5ZzK9hlZGTgdDqJjo4uNT06Opq9e/eWax2vvPIK9evXp0+fPu5sGoCkpCS3l6kIT21HKs9/e9UUW583abD3Uxru+gDH4fU43h5IWrObORL3IAUhda0usEL8t1/+R73yHeqV7/BEr9wKdpX11ltvsWTJEt5//32Cg4PdXj4xMRGHw1ENlZmcTidJSUnVvh2pvBrTq+5Xw9nHcS17Hvvmj4k59CXRx1dhXPsUxtUPQYD7v0dWqDH98gPqle9Qr3xHZXtVtHx5uBXsoqKicDgcF10okZ6eTkxMzGWXffvtt3nrrbeYNWsWcXFx7my2mMPh8MgfXk9tRyqvRvQqsikMfxOufhA+n4jtyAZs3zwLP70HA5+B+NvNK2x9QI3ol59Qr3yHeuU7PNErt/41CAoKomPHjqUufCi6EKJr166XXO7f//43r7/+OjNnziQxMbHi1YrUZE2vggeWwrA3IbwhZOyDT8bAG31gyzxw6TwbEZGazu3/5o8dO5a5c+cyf/589uzZw7PPPkt2djbDhw8HYOLEiUybNq14/rfeeovp06fzl7/8hSZNmpCamkpqaiqZmbqNg4jb7Hbo/Et4dAP0+z0ER0BqMnx6v3mD481zwVlgdZUiImIRt8+xu/XWWzl58iQzZswgNTWV+Ph4Zs6cWXwo9ujRo9hLHBb6+OOPyc/P57HHHiu1ngkTJvDoo49WsnyRGio4HPr/AXo9DOvegtWvQdpO+OxB+G6qeeuUxJHmbVRERKTGqNDf+qNGjWLUqFFlfjZ79uxS75ctW1aRTYhIeYRGQr+J0HNcYcD7J5zcAwvGwfKpcO1T5h4+R6DVlYqIiAf4xhnXInJ5IXXguqfgd0kw8FkIizYfS/a/CfCPbrDhXcjPsbhIERGpbgp2Iv4kuDb0fdwMeDc+D7XqwamDsPC38LcOsHQynDpkdZUiIlJNFOxE/FFQLbjmMfjtZrh5CtRpAlnpsPJVmN4JPr4H9i7Xo8pERPyMgp2IPwsKg96PmAHvztnQ8lowXLB9Ebx/G7zWE9b9G3LPWl2piIhUAQU7kZrAEQAdboMxi+CRNXDVAxBYC9J2wJKnYFo8LJkIabusrlRERCpBwU6kpqkfD0NehSeTYdDLEN0W8s7Cujfhn1fBe7fBzx9D7jmrKxURETfpJlciNVVIBPR8CHo8CPu+Mw/J7vgc9i03h8AwiB8Kne6EVtfrnngiIj5Af1OL1HR2O7QZYA4ZB8y9dZs/hpN7YfN/zCG8ASTcAZ3vgoadwGazumoRESmDgp2InBfVAq6fZN70+MgGM+RtmQfnjsOa18yhXhx0ust8skVkM6srFhGREhTsRORiNhs0vcocbpkCu5eae+62L4HU7fDNZHNo3hviBkPsrRDdxuqqRURqPAU7Ebk8RyDEDjKHnNOw7X9myNu/Eg6uNoev/mTuyYsbDLGDoXFX8xCviIh4lIKdiJRfSAR0u9ccTh+BHUvMe+LtX2nuyUvdDiumQXhDMwjGDYFW14JNf9WIiHiC/rYVkYqJaAJXP2gO2adg19ewY7H5eu4YbJhlDkG1sbUZQHRQe2gVA3VbWF25iIjfUrATkcoLjYROI82hIBf2rTBD3vYlcO4Y9uT/0hLg579CdDtofb05tOxrLisiIlVCwU5EqlZAMLQbaA63ToOUjbi2LyZryxJqnd6BLX0XpO+C9f8Gmx2adD8f9Jr2MJcXEZEKUbATkepjt0PT7hiNurAjajBd4lrhOPgD7P0W9n4H6bvh8Hpz+P6v5k2Rm/eGFr2hWS9o0g2Caln9LUREfIaCnYh4TkgExA8xB4BTh8ynXOwpDHpZabDnG3MAsAdAw0Qz5DW7Gpr3gjqNLStfRMTbKdiJiHUim0HXUebgcsGJbbB/BRxaCwfXwtkUSNloDmvfMJeJaH4+5DXtAfU7QECQtd9DRMRLKNiJiHew26Fhgjn0ehgMA04fgkPr4OAaOLQGjm+F0wfNYcunhcsFQoMO0KgLNO4CjTpD/Y4QGGLltxERsYSCnYh4J5sNIpubQ+Id5rTcs3D4RzPsHVpjPvYs5zQc/dkcfnrPnM8eAPXjzZDXqIt5w+T6HSAozLKvIyLiCQp2IuI7gmtDm/7mAOZevVMHIGUTHN1khruUTZB9Eo4lmcPGDwoXtkFUSzPw1Y83g169OIhppytxRcRvKNiJiO+yFYa1qJbQ8RfmNMOA04dLB72jmyAzFTL2mcOOJSXW4YDotlA/rkTYaw91W0FgqKe/kYhIpSjYiYh/sdnMizIim0H80PPTz6VCajKcuGDIPQ1pO8xh239LrggimkJ0GzP4FQ9tzAs4HPrrU0S8j/5mEpGaIbyeObS67vw0w4CzR82rcU8kw4nt5nj6HjPwnT5kDnu/K70ue6C5lzC6DUS2gKgW5mtkc3M8JMKT30xEpJiCnYjUXDabeV+8Oo2h7cDz0w0DstLNGyin7zaDXtHryT1QkGM+PSN9V9nrDYk8H/IiS4S+Oo2hThMIq2tuW0SkiinYiYhcyGaDWjHm0LxX6c9cLjhzxAx46Xvg1EHzAo6MA+ZrVjrknIJjp+DY5rLXHxByPuTVaWKOR5QYr90IwmLMW8CIiLhBwU5ExB12+/lz+Fpff/HnuecuCHuF46cPwZkU8yKOghw4udccLsXmgPD6EN7AHGo3gPCG5rTaDc3x2g3MAKjbuIhIIQU7EZGqFBxu3jC5QYeyP8/PMc/rO3PEDHpnjsDpovHDheEvDQynOd/Zo1feZmAtqBUNteqZQa9WvYvfh9U1h9C65m1jdChYxC8p2ImIeFJgiHkrlbqtLj2PM9/cs3f2GJw7AeeOwdnjcK5wKDndmQf5mXAq09w7WB72AAiNMkNeaNT5wBcaiS0kipi0c9gC95rTQyLNi0FCC18dgVXxUxCRaqJgJyLibRyB5y/quBzDMJ/GkZVm7uXLTDMDYcn3WUXTTppDQTa4CsxpmakXrdIOtABIusQ2A2uZAa8o7AXXMfcABteGkKLxC1+LxsMhqJa5Dp0/KFItFOxERHyVzWaGqZA6ULd1+ZbJzzYDXvZJyM44P55lvndlpnPm+EEigg1suWfMR7Zln4K8s4XLZ5rD2ZTK1R5UGPKKXoNrl34fVAsCw8zzBwNrXfAadv7zwNDSr45AHWaWGk3BTkSkJgkMNa/AjWhS5seG08meTZvo0qULDofj/AfOAigKejmnzge+3LOFw5nzrzlnyph+FvLOgeEy15d3zhw4XrXfz2Y/H/QCQgsDX+EQEFL4Gmx+FhB8fnpAiHmYvGg8INgcHMHnx4uml5zmCDo/ze5QqBTLKdiJiMiVOQLOX4BRUYZh7jEsCnW5ha95mYXBL/P8Z3lZkJ9lTsvPKnyfefH0/GzztSgwGq4SodHTbCWCX5AZ+oqDX6A53RFUOB5YYjyo9Lg98Pw8F40HFM9jszmITDkMoSmF2wgwz58sWsbuKDEecPHguOC9za5g6gcU7ERExDNsNvNQalAYUL/q1msY5gUn+VnmrWSKA19O6fBXkGueY1iQa04ryCmcP+f8eNF7Z27h/IWDM7fw85LTcwCjZCHn15FbdV/vUuxAG4ANVbnSkiHQXiL0OQrHy3i1Oc6/tznOL1dqur30vMWflTGt5Lylxm0Xz1e0PZv9/PviZeylh1LTHOeD7KXmL/n5pQZHoHkDci8KxAp2IiLi22w2cw9ZQJBnt2sY4HKeD4HOPHMoyDOnlRwvyANXfuE8+efnveR4gfnqyjfHSy7rKgBnPoYzn3NnMggPDcbmKjCnF35WajlXQeF40ZB/6e/kyr/853Kxng/DoKlWV1FMwU5ERKQibLbCQ6MB5sUcHuZyOtlZ1vmQV2IY5iHrUmHwguDncpqD4SwxvXBa0XvDaS5nXDivq8R44avhKjFPydfLTL/os5LTXBdPL+tzw3U+gBvOwu9+wTKuC5YvuVzRz+pSg81e/guXPETBTkREpCax2c4fziTY6mqkiulGQiIiIiJ+QsFORERExE9UKNjNmTOHAQMGkJiYyMiRI9m8efNl5//888+55ZZbSExMZOjQoSxfvrxCxYqIiIjIpbkd7JYsWcKUKVMYP3488+fPJy4ujgceeID09PQy5//pp5948sknueOOO1iwYAE33HAD48ePZ+fOnZUuXkRERETOczvYzZo1izvvvJMRI0bQtm1bJk+eTEhICPPmzStz/vfff59rr72WX//617Rp04bf/e53dOjQgQ8++KDSxYuIiIjIeW5dFZuXl8fWrVt56KGHiqfZ7Xb69OnDxo0by1xm06ZNjBkzptS0vn37snTpUreLdTqdbi9TkfVX93ak8tQr36J++Q71yneoV76jsr1yZzm3gl1GRgZOp5Po6OhS06Ojo9m7d2+Zy6SlpRETE3PR/Glpae5sGoCkpCS3l6kIT21HKk+98i3ql+9Qr3yHeuU7PNErn7qPXWJions3YXST0+kkKSmp2rcjlade+Rb1y3eoV75DvfIdle1V0fLl4Vawi4qKwuFwXHShRHp6+kV75YrExMRctHfucvNfjsPh8MgfXk9tRypPvfIt6pfvUK98h3rlOzzRK7cunggKCqJjx46sXr26eJrL5WL16tV07dq1zGW6dOnCmjVrSk374Ycf6NKli/vVioiIiMgluX1V7NixY5k7dy7z589nz549PPvss2RnZzN8+HAAJk6cyLRp04rnHz16NCtWrOCdd95hz549/OMf/2DLli2MGjWq6r6FiIiIiLh/jt2tt97KyZMnmTFjBqmpqcTHxzNz5sziQ6tHjx7Fbj+fF7t168Yrr7zC3//+d1599VVatmzJa6+9Rvv27avuW4iIiIhIxS6eGDVq1CX3uM2ePfuiaYMGDWLQoEEV2ZSIiIiIlJOeFSsiIiLiJxTsRERERPyEgp2IiIiIn/CJGxQbhgHokWJynnrlW9Qv36Fe+Q71yndU1SPFivLQ5diM8sxlsby8PD0yRURERGq0xMREgoKCLjuPTwQ7l8tFQUEBdrsdm81mdTkiIiIiHmMYBi6Xi4CAgFK3lCuLTwQ7EREREbkyXTwhIiIi4icU7ERERET8hIKdiIiIiJ9QsBMRERHxEwp2IiIiIn5CwU5ERETETyjYiYiIiPgJBTsRERERP6FgV8KcOXMYMGAAiYmJjBw5ks2bN1tdUo23fv16xo0bR9++fYmNjWXp0qWlPjcMg+nTp9O3b186derEmDFj2L9/vzXF1nBvvvkmI0aMoGvXrvTu3ZtHHnmEvXv3lponNzeXyZMn07NnT7p27cqjjz5KWlqaRRXXXB9++CFDhw6lW7dudOvWjbvuuovly5cXf64+ea+33nqL2NhYXnzxxeJp6pf3+Mc//kFsbGyp4ZZbbin+3BO9UrArtGTJEqZMmcL48eOZP38+cXFxPPDAA6Snp1tdWo2WlZVFbGwszzzzTJmf//vf/2b27Nk8++yzzJ07l9DQUB544AFyc3M9XKmsW7eOe+65h7lz5zJr1iwKCgp44IEHyMrKKp7nL3/5C99++y1///vfmT17NidOnGDChAkWVl0zNWzYkKeeeorPPvuMefPm0atXL8aPH8+uXbsA9clbbd68mY8//pjY2NhS09Uv79KuXTtWrlxZPHz44YfFn3mkV4YYhmEYd9xxhzF58uTi906n0+jbt6/x5ptvWliVlNS+fXvj66+/Ln7vcrmMa665xpg5c2bxtDNnzhgJCQnGokWLrChRSkhPTzfat29vrFu3zjAMszcdO3Y0Pv/88+J5du/ebbRv397YuHGjRVVKkR49ehhz585Vn7zUuXPnjJtuuslYtWqVMWrUKOOFF14wDEO/V95mxowZxm233VbmZ57qlfbYAXl5eWzdupU+ffoUT7Pb7fTp04eNGzdaWJlczuHDh0lNTS3Vt9q1a9O5c2f1zQucPXsWgIiICAC2bNlCfn5+qX61adOGxo0bs2nTJitKFMDpdLJ48WKysrLo2rWr+uSlnnvuOfr161eqL6DfK2904MAB+vbtyw033MCTTz5JSkoK4LleBVTZmnxYRkYGTqeT6OjoUtOjo6MvOkdIvEdqaipAmX3T+SXWcrlc/OUvf6Fbt260b98egLS0NAIDA6lTp06peaOjo4t7KZ6zY8cOfvnLX5Kbm0tYWBivvfYabdu2JTk5WX3yMosXL2bbtm18+umnF32m3yvv0qlTJ6ZMmUKrVq1ITU3ltdde45577mHhwoUe65WCnYhUucmTJ7Nr165S55aId2nVqhULFizg7NmzfPnll0yaNIkPPvjA6rLkAkePHuXFF1/knXfeITg42Opy5Ar69etXPB4XF0fnzp3p378/n3/+OSEhIR6pQYdigaioKBwOx0UXSqSnpxMTE2NRVXIl9erVA1DfvMxzzz3Hd999x3vvvUfDhg2Lp8fExJCfn8+ZM2dKzZ+enl7cS/GcoKAgWrRoQUJCAk8++SRxcXG8//776pOX2bp1K+np6QwfPpwOHTrQoUMH1q1bx+zZs+nQoYP65eXq1KlDy5YtOXjwoMd6pWCH+Rdcx44dWb16dfE0l8vF6tWr6dq1q4WVyeU0bdqUevXqlerbuXPn+Pnnn9U3CxiGwXPPPcfXX3/Ne++9R7NmzUp9npCQQGBgYKl+7d27l5SUFLp06eLhauVCLpeLvLw89cnL9OrVi4ULF7JgwYLiISEhgaFDhxaPq1/eKzMzk0OHDlGvXj2P9UqHYguNHTuWSZMmkZCQQKdOnXjvvffIzs5m+PDhVpdWo2VmZnLw4MHi94cPHyY5OZmIiAgaN27M6NGjeeONN2jRogVNmzZl+vTp1K9fn4EDB1pYdc00efJkFi1axOuvv06tWrWKzxmpXbs2ISEh1K5dmxEjRjB16lQiIiIIDw/nhRdeoGvXrvoHyMOmTZvGddddR6NGjcjMzGTRokWsW7eOt99+W33yMuHh4cXnqRYJCwsjMjKyeLr65T1eeukl+vfvT+PGjTlx4gT/+Mc/sNvtDBkyxGO/Wwp2hW699VZOnjzJjBkzSE1NJT4+npkzZ+qQnsW2bNnC6NGji99PmTIFgGHDhjF16lQefPBBsrOzefrppzlz5gzdu3dn5syZOhfFAh999BEA9957b6npU6ZMKf4P0h//+EfsdjuPPfYYeXl59O3b95L3KJTqk56ezqRJkzhx4gS1a9cmNjaWt99+m2uuuQZQn3yN+uU9jh07xhNPPMGpU6eoW7cu3bt3Z+7cudStWxfwTK9shmEYVbpGEREREbGEzrETERER8RMKdiIiIiJ+QsFORERExE8o2ImIiIj4CQU7ERERET+hYCciIiLiJxTsRERERPyEgp2IiIiIn1CwExEREfETCnYiIiIifkLBTkRERMRPKNiJiIiI+In/D+PsxqdkSuYTAAAAAElFTkSuQmCC"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "id": "iUqc-Nh_CWN0"
   },
   "source": [
    "## ⚡ Now we can save the vectors and visualize it using [TF projector](https://projector.tensorflow.org/)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "YpCimrA3CWN0",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:20:44.510246Z",
     "start_time": "2025-03-31T18:20:44.491741Z"
    }
   },
   "source": [
    "weights = model.get_layer('w2v_embedding').get_weights()[0]\n",
    "vocab = vectorize_layer.get_vocabulary()"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "FRE8JOBrCWN0",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:20:44.816954Z",
     "start_time": "2025-03-31T18:20:44.557834Z"
    }
   },
   "source": [
    "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for index, word in enumerate(vocab):\n",
    "    if index == 0:\n",
    "        continue  # skip 0, it's padding.\n",
    "    vec = weights[index]\n",
    "    out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "    out_m.write(word + \"\\n\")\n",
    "\n",
    "out_v.close()\n",
    "out_m.close()"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agL7hevtCWN0"
   },
   "source": [
    "# No Word2Vec tutorial will be ever complete without the similar word search 🙂"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "2-4vUJWiCWN0",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:20:44.852645Z",
     "start_time": "2025-03-31T18:20:44.847327Z"
    }
   },
   "source": [
    "id2word = {k: v for k, v in enumerate(vocab)}\n",
    "word2id = {v: k for k, v in enumerate(vocab)}"
   ],
   "outputs": [],
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eB4xkCloCWN1"
   },
   "source": [
    "# So here we go, we will search the closest vectors for selected words\n",
    "* 🔎 How is it done?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "OLCJiOHiCWN1",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:20:45.105687Z",
     "start_time": "2025-03-31T18:20:44.889438Z"
    }
   },
   "source": [
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "distance_matrix = cosine_distances(weights)\n",
    "print(distance_matrix.shape)\n",
    "\n",
    "similar_words = {search_term: [id2word[idx] for idx in distance_matrix[word2id[search_term]].argsort()[1:6]]\n",
    "                 for search_term in ['harry', 'hagrid', 'potter', 'go', 'he', 'the', 'one', 'hermione']}\n",
    "\n",
    "similar_words"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6036, 6036)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'harry': [np.str_('dreamily'),\n",
       "  np.str_('curl'),\n",
       "  np.str_('invisibility'),\n",
       "  np.str_('towered'),\n",
       "  np.str_('explained')],\n",
       " 'hagrid': [np.str_('daughter'),\n",
       "  np.str_('strangled'),\n",
       "  np.str_('sounded'),\n",
       "  np.str_('football'),\n",
       "  np.str_('wriggles')],\n",
       " 'potter': [np.str_('important'),\n",
       "  np.str_('sleeps'),\n",
       "  np.str_('cloak'),\n",
       "  np.str_('bravely'),\n",
       "  np.str_('early')],\n",
       " 'go': [np.str_('bananas'),\n",
       "  np.str_('drift'),\n",
       "  np.str_('frighten'),\n",
       "  np.str_('persuade'),\n",
       "  np.str_('manage')],\n",
       " 'he': [np.str_('bravo'),\n",
       "  np.str_('glinting'),\n",
       "  np.str_('creeps'),\n",
       "  np.str_('health'),\n",
       "  np.str_('spreading')],\n",
       " 'the': [np.str_('arrivals'),\n",
       "  np.str_('promise'),\n",
       "  np.str_('sounding'),\n",
       "  np.str_('fight'),\n",
       "  np.str_('whippy')],\n",
       " 'one': [np.str_('went'),\n",
       "  np.str_('footsteps'),\n",
       "  np.str_('later'),\n",
       "  np.str_('thumbs'),\n",
       "  np.str_('law')],\n",
       " 'hermione': [np.str_('guarding'),\n",
       "  np.str_('granger'),\n",
       "  np.str_('talent'),\n",
       "  np.str_('vol'),\n",
       "  np.str_('footsteps')]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9_EdtfbDCWN1"
   },
   "source": [
    "# The results are clearly far from ideal 😪\n",
    "![w2v_meme_01](https://github.com/rasvob/VSB-FEI-Deep-Learning-Exercises/blob/main/images/dl_07_meme_01.png?raw=true)\n",
    "\n",
    "## 🔎 What happend? Did we do anything wrong?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "id": "afdWuOV9CWN1"
   },
   "source": [
    "# Ok, let's try again with pre-trained vectors"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-31T18:20:45.128242Z",
     "start_time": "2025-03-31T18:20:45.123981Z"
    }
   },
   "source": [
    "if not os.path.exists('glove.6B.zip') and not os.path.exists('glove.6B.50d.txt'):\n",
    "    print(\"Downloading GloVe embeddings...\")\n",
    "    !wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "else:\n",
    "    print(\"GloVe embeddings already downloaded.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe embeddings already downloaded.\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "id": "OoEAsJbSCWN2",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:20:45.176187Z",
     "start_time": "2025-03-31T18:20:45.170506Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if os.path.exists('glove.6B.zip') and not os.path.exists('glove.6B.50d.txt'):\n",
    "    print(\"Extracting GloVe embeddings...\")\n",
    "    !unzip -q glove.6B.zip\n",
    "else:\n",
    "    print(\"GloVe embeddings already extracted.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe embeddings already extracted.\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "ih5Wu4r7CWN2",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:20:54.126503Z",
     "start_time": "2025-03-31T18:20:45.232236Z"
    }
   },
   "source": [
    "path_to_glove_file = 'glove.6B.50d.txt'\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file) as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "id": "YZ-_hXWYCWN2"
   },
   "source": [
    "## 💡 This is how the embedding latent vector looks like for the word 'audi' and 'bmw'"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "IAPoS2ltCWN2",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:20:54.656216Z",
     "start_time": "2025-03-31T18:20:54.650326Z"
    }
   },
   "source": [
    "embeddings_index['audi']"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.051355 ,  0.11694  ,  1.0251   ,  0.12414  , -0.83236  ,\n",
       "        1.0288   , -0.64566  , -1.4468   , -0.89265  , -0.32658  ,\n",
       "        0.66507  , -0.65524  , -1.8323   , -1.0347   ,  0.13486  ,\n",
       "       -0.033565 , -0.2208   ,  1.855    , -0.2495   , -0.84343  ,\n",
       "        0.14318  , -0.81258  , -0.84232  ,  1.1247   , -0.075604 ,\n",
       "       -0.30852  , -0.79071  ,  0.80721  , -0.24747  , -0.029263 ,\n",
       "        0.2684   ,  0.6531   ,  0.48872  ,  1.1838   ,  0.5606   ,\n",
       "       -0.68087  ,  0.25192  ,  0.98091  , -1.0433   , -0.27203  ,\n",
       "        1.1912   , -0.88594  ,  0.022038 , -0.82012  , -0.0022396,\n",
       "       -0.68251  ,  0.12713  ,  0.85041  ,  1.002    ,  0.33904  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "kP3_zzjECWN3",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:20:54.710889Z",
     "start_time": "2025-03-31T18:20:54.706153Z"
    }
   },
   "source": [
    "embeddings_index['bmw']"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.70038 , -0.16073 ,  1.3423  ,  0.63331 , -0.21958 ,  0.31944 ,\n",
       "       -0.67042 , -0.94041 , -0.56935 , -0.67842 ,  0.39705 , -0.18964 ,\n",
       "       -2.2101  , -0.90947 ,  0.95511 , -0.01321 , -0.32738 ,  1.1554  ,\n",
       "       -0.48464 , -1.7606  , -0.051495, -1.0745  , -1.183   ,  0.68672 ,\n",
       "       -0.107   , -0.42152 , -0.15516 ,  0.12724 , -0.42114 ,  0.30905 ,\n",
       "        0.59784 ,  0.050149,  0.24022 ,  0.86494 ,  0.63488 , -0.75644 ,\n",
       "       -0.09189 ,  1.0218  , -0.96638 , -0.90508 ,  0.80575 , -0.75225 ,\n",
       "        0.7642  , -0.94425 ,  0.4609  ,  0.11877 ,  0.24907 ,  0.066667,\n",
       "        0.59622 ,  0.1275  ], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wu7UNcQnCWN3"
   },
   "source": [
    "## 💡 Hypothesis: The cosine distance of the car brands should be smaller than with some random word\n",
    "* 🔎 Why?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "xA99Vi7ZCWN3",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:20:54.968859Z",
     "start_time": "2025-03-31T18:20:54.963395Z"
    }
   },
   "source": [
    "cosine(embeddings_index['audi'], embeddings_index['bmw'])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.16636306)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "JNha4DIGCWN3",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:20:55.199912Z",
     "start_time": "2025-03-31T18:20:55.195482Z"
    }
   },
   "source": [
    "cosine(embeddings_index['audi'], embeddings_index['king'])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(1.0900573)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhKjCjU1CWN3"
   },
   "source": [
    "## 🚀 For trying the famous `queen -> king` example we need to build the embedding matrix\n",
    "\n",
    "![w2v_meme_03](https://github.com/rasvob/VSB-FEI-Deep-Learning-Exercises/blob/main/images/dl_07_meme_03.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "nwqo5yu-CWN3",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:20:55.854312Z",
     "start_time": "2025-03-31T18:20:55.432934Z"
    }
   },
   "source": [
    "num_tokens = len(embeddings_index.keys())\n",
    "embedding_dim = 50\n",
    "hits = 0\n",
    "misses = 0\n",
    "word2id = {k: i for i, (k, v) in enumerate(embeddings_index.items())}\n",
    "id2word = {v: k for k, v in word2id.items()}\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word2id.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    embedding_matrix[i] = embedding_vector\n"
   ],
   "outputs": [],
   "execution_count": 54
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2deweHE6CWN3"
   },
   "source": [
    "## Finding the closest words is pretty easy now"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "TYsr6_hkCWN3",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:20:56.467177Z",
     "start_time": "2025-03-31T18:20:56.335966Z"
    }
   },
   "source": [
    "c_w = cosine_distances(embedding_matrix[word2id['man']].reshape(-1, 50), embedding_matrix)"
   ],
   "outputs": [],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "kcqG4mLGCWN3",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:20:57.054669Z",
     "start_time": "2025-03-31T18:20:57.033678Z"
    }
   },
   "source": [
    "for x in c_w.argsort().ravel()[1:6]:\n",
    "    print(id2word[x])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "woman\n",
      "boy\n",
      "another\n",
      "old\n",
      "one\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "5OzoNl_HCWN4",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:20:57.780433Z",
     "start_time": "2025-03-31T18:20:57.628649Z"
    }
   },
   "source": [
    "c_w = cosine_distances(embedding_matrix[word2id['woman']].reshape(-1, 50), embedding_matrix)"
   ],
   "outputs": [],
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "4dFx7-wACWN4",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:20:58.949485Z",
     "start_time": "2025-03-31T18:20:58.923575Z"
    }
   },
   "source": [
    "for x in c_w.argsort().ravel()[1:6]:\n",
    "    print(id2word[x])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "girl\n",
      "man\n",
      "mother\n",
      "her\n",
      "boy\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bPLt8RZECWN4"
   },
   "source": [
    "## The idea is that using the difference between `man` and `woman` should be simillar as `king` and `queen`\n",
    "* 💡 Thus it should be possible to use the difference for searching for analogies"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "jxnaz4_vCWN4",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:20:58.994717Z",
     "start_time": "2025-03-31T18:20:58.991335Z"
    }
   },
   "source": [
    "dist = embeddings_index['man'] - embeddings_index['woman']"
   ],
   "outputs": [],
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "Uh0Qy5j6CWN6",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:20:59.573158Z",
     "start_time": "2025-03-31T18:20:59.568547Z"
    }
   },
   "source": [
    "dist"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.087144  , -0.2182    ,  0.40985996,  0.03922001,  0.10320008,\n",
       "       -0.94165003,  0.06042001, -0.32988   , -0.46144   ,  0.35962   ,\n",
       "       -0.31102   ,  0.86824   , -0.96006   , -0.01073003, -0.24337   ,\n",
       "       -0.08193001,  1.02722   ,  0.21122   , -0.695044  ,  0.00222   ,\n",
       "       -0.29106003, -0.50530005,  0.099454  , -0.40445   , -0.30181003,\n",
       "       -0.1355002 ,  0.06060004,  0.07131001,  0.19245   ,  0.06115001,\n",
       "        0.3204    , -0.07165   ,  0.13337001,  0.25068715,  0.14292999,\n",
       "        0.224957  ,  0.14899999, -0.048882  , -0.12191002,  0.27362   ,\n",
       "        0.16547601,  0.20426002, -0.54376   ,  0.27142498,  0.10244995,\n",
       "        0.32108003, -0.2516    ,  0.33454996,  0.04371002, -0.01258   ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "sTBZi3HkCWN6",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:21:00.113272Z",
     "start_time": "2025-03-31T18:21:00.110251Z"
    }
   },
   "source": [
    "summed = embeddings_index['queen'] + dist"
   ],
   "outputs": [],
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "96HJ7tIaCWN7",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:21:00.648750Z",
     "start_time": "2025-03-31T18:21:00.643280Z"
    }
   },
   "source": [
    "summed"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.465684  ,  1.6051    , -0.85494   , -0.06507999,  0.46149006,\n",
       "       -0.34136003, -0.11496   ,  0.50779   , -0.518238  , -0.39833   ,\n",
       "       -0.08420999,  1.85411   , -0.35419   , -0.32492003,  0.04539999,\n",
       "        0.4782    ,  0.25266004,  0.282641  , -1.269144  ,  0.21564001,\n",
       "        0.28568   , -0.11850005, -0.02628601, -0.12433001, -0.02046004,\n",
       "       -1.9408002 , -0.9814999 , -0.12123999, -0.3613    ,  0.00662401,\n",
       "        1.8778    ,  0.32131   , -0.11412999,  0.59319717,  0.59657997,\n",
       "        0.38732702,  0.67364   , -0.119154  , -0.95935005, -0.75898004,\n",
       "        0.624936  ,  0.45728   , -0.72213   , -0.46255502, -0.09780005,\n",
       "        0.55578005, -0.81254995, -1.9493501 ,  0.05298533, -0.61542   ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "QOCnso01CWN7",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:21:01.267138Z",
     "start_time": "2025-03-31T18:21:01.148857Z"
    }
   },
   "source": [
    "res = cosine_distances(summed.reshape(-1, 50), embedding_matrix)"
   ],
   "outputs": [],
   "execution_count": 63
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xBRpH0mZCWN7"
   },
   "source": [
    "# And here we go 🙂"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "Sk1GTseLCWN7",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:21:02.176894Z",
     "start_time": "2025-03-31T18:21:02.157799Z"
    }
   },
   "source": [
    "for x in res.argsort().ravel()[1:6]:\n",
    "    print(id2word[x])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "king\n",
      "prince\n",
      "crown\n",
      "coronation\n",
      "royal\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RZAxp3CXCWN7"
   },
   "source": [
    "![w2v_meme_02](https://github.com/rasvob/VSB-FEI-Deep-Learning-Exercises/blob/main/images/dl_07_meme_02.png?raw=true)\n",
    "\n",
    "# We will also learn how to use RNN as a text generator! 🙂\n",
    "* There are two main ways for solving the task\n",
    "    * 💡 Word-based model\n",
    "    * 💡 Character-based model\n",
    "    \n",
    "* We have relatively small dataset thus we will use the **Character-based model** as it works better with smaller datasets\n",
    "    * 💡 We will also simplify the task for using only lower case letters\n",
    "\n",
    "* 🔎 If we would have very large text corpus available, which way would be better and why?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "g_cnhL6lCWN7",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:21:02.243064Z",
     "start_time": "2025-03-31T18:21:02.212641Z"
    }
   },
   "source": [
    "text_hp = tf.data.TextLineDataset(path_to_file).skip(1).filter(lambda x: tf.cast(tf.strings.length(x), bool)).filter(\n",
    "    lambda y: not tf.strings.regex_full_match(y, 'CHAPTER.*')).map(lambda z: tf.strings.lower(z))"
   ],
   "outputs": [],
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "WqEhYpAcCWN7",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:21:04.723275Z",
     "start_time": "2025-03-31T18:21:02.729718Z"
    }
   },
   "source": [
    "txt_one_line = ''\n",
    "for x in text_hp.as_numpy_iterator():\n",
    "    txt_one_line += str(x)[2:-1]"
   ],
   "outputs": [],
   "execution_count": 66
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "9pZwQcV1CWN7",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:21:05.304073Z",
     "start_time": "2025-03-31T18:21:05.299705Z"
    }
   },
   "source": [
    "txt_one_line[:150]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the boy who livedmr. and mrs. dursley, of number four, privet drive, were proud to saythat they were perfectly normal, thank you very much. they were '"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 67
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HpBk6quzCWN8"
   },
   "source": [
    "## Build an array of letters from the whole text and filter out everything which is not lower-case letters and spaces"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "jJ7uhgtpCWN8",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:21:05.990642Z",
     "start_time": "2025-03-31T18:21:05.908812Z"
    }
   },
   "source": [
    "letters = []\n",
    "for x in txt_one_line:\n",
    "    if x >= 'a' and x <= 'z' or x == ' ':\n",
    "        letters.append(x)"
   ],
   "outputs": [],
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "fQ7whzaaCWN8",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:21:06.471880Z",
     "start_time": "2025-03-31T18:21:06.467685Z"
    }
   },
   "source": [
    "letters[:10]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['t', 'h', 'e', ' ', 'b', 'o', 'y', ' ', 'w', 'h']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 69
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wSqEvWXQCWN8"
   },
   "source": [
    "# We have corpus of 405551 characters available"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "C-5nRfl3CWN8",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:21:07.422862Z",
     "start_time": "2025-03-31T18:21:07.418143Z"
    }
   },
   "source": [
    "len(letters)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "405551"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 70
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPnZ3TbiCWN8"
   },
   "source": [
    "### 💡 But only 27 unique tokens"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "BYM5BaTECWN8",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:21:07.942858Z",
     "start_time": "2025-03-31T18:21:07.936097Z"
    }
   },
   "source": [
    "chars = sorted(list(set(letters)))\n",
    "print(\"Total chars:\", len(chars))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chars: 27\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZqC588EPCWN9"
   },
   "source": [
    "## We will build `ID -> CHAR` and `CHAR -> ID` lookup tables"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "j7w3Ubn5CWN9",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:21:07.997573Z",
     "start_time": "2025-03-31T18:21:07.993989Z"
    }
   },
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ],
   "outputs": [],
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "EdF_t-YRCWN9",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:21:08.489582Z",
     "start_time": "2025-03-31T18:21:08.484958Z"
    }
   },
   "source": [
    "char_indices"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " 'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "L7kt2MfSCWN-",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:21:08.946586Z",
     "start_time": "2025-03-31T18:21:08.941975Z"
    }
   },
   "source": [
    "indices_char"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ' ',\n",
       " 1: 'a',\n",
       " 2: 'b',\n",
       " 3: 'c',\n",
       " 4: 'd',\n",
       " 5: 'e',\n",
       " 6: 'f',\n",
       " 7: 'g',\n",
       " 8: 'h',\n",
       " 9: 'i',\n",
       " 10: 'j',\n",
       " 11: 'k',\n",
       " 12: 'l',\n",
       " 13: 'm',\n",
       " 14: 'n',\n",
       " 15: 'o',\n",
       " 16: 'p',\n",
       " 17: 'q',\n",
       " 18: 'r',\n",
       " 19: 's',\n",
       " 20: 't',\n",
       " 21: 'u',\n",
       " 22: 'v',\n",
       " 23: 'w',\n",
       " 24: 'x',\n",
       " 25: 'y',\n",
       " 26: 'z'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 74
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oGRMz61hCWN-"
   },
   "source": [
    "## ⚡ We need to create fixed length sequences for the model\n",
    "* We will shift the sliding window of `SEQ_LEN` by `step` and for `X,y` pair\n",
    "    * 💡 Input is array of `SEQ_LEN` letters output is just **1** letter which comes after the sequence"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "PG9176qKCWN-",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:21:10.321130Z",
     "start_time": "2025-03-31T18:21:09.407090Z"
    }
   },
   "source": [
    "SEQ_LEN = 40\n",
    "step = 1\n",
    "X, y = [], []\n",
    "for i in range(0, len(letters) - SEQ_LEN, step):\n",
    "    seq, ch = letters[i:i + SEQ_LEN], letters[i + SEQ_LEN]\n",
    "    X.append(seq)\n",
    "    y.append(ch)"
   ],
   "outputs": [],
   "execution_count": 75
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLc7fv8UCWN-"
   },
   "source": [
    "## Let's take a look at the example\n",
    "* 💡 Focus on the last letter of the second sequence"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "odpv_bkkCWN-",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:21:10.775859Z",
     "start_time": "2025-03-31T18:21:10.771702Z"
    }
   },
   "source": [
    "print(X[0])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t', 'h', 'e', ' ', 'b', 'o', 'y', ' ', 'w', 'h', 'o', ' ', 'l', 'i', 'v', 'e', 'd', 'm', 'r', ' ', 'a', 'n', 'd', ' ', 'm', 'r', 's', ' ', 'd', 'u', 'r', 's', 'l', 'e', 'y', ' ', 'o', 'f', ' ', 'n']\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "rmbD-2J8CWN-",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:21:11.269917Z",
     "start_time": "2025-03-31T18:21:11.266340Z"
    }
   },
   "source": [
    "print(X[1])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['h', 'e', ' ', 'b', 'o', 'y', ' ', 'w', 'h', 'o', ' ', 'l', 'i', 'v', 'e', 'd', 'm', 'r', ' ', 'a', 'n', 'd', ' ', 'm', 'r', 's', ' ', 'd', 'u', 'r', 's', 'l', 'e', 'y', ' ', 'o', 'f', ' ', 'n', 'u']\n"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "6h6jUbJzCWN_",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:21:11.734114Z",
     "start_time": "2025-03-31T18:21:11.729661Z"
    }
   },
   "source": [
    "y[0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'u'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 78
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gtksa1mHCWN_"
   },
   "source": [
    "### 📌 Characted level RNN uses usually one-hot encoding as we work just with a few unique tokens\n",
    "* So no complex embedding is needed"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "kpSAIFGYCWN_",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:21:13.924711Z",
     "start_time": "2025-03-31T18:21:12.193806Z"
    }
   },
   "source": [
    "X_ohe = np.zeros((len(X), SEQ_LEN, len(chars)), dtype=bool)\n",
    "y_ohe = np.zeros((len(X), len(chars)), dtype=bool)\n",
    "for i, sentence in enumerate(X):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X_ohe[i, t, char_indices[char]] = 1\n",
    "    y_ohe[i, char_indices[y[i]]] = 1"
   ],
   "outputs": [],
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "30lgmpVfCWN_",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:21:14.424698Z",
     "start_time": "2025-03-31T18:21:14.419257Z"
    }
   },
   "source": [
    "X_ohe.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(405511, 40, 27)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "dHXXe2MsCWN_",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:21:14.912160Z",
     "start_time": "2025-03-31T18:21:14.908376Z"
    }
   },
   "source": [
    "y_ohe.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(405511, 27)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 81
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "STVyIL2wCWN_"
   },
   "source": [
    "# 🚀 The final step is the model definition and training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "5TOlBALACWOA",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:21:15.551997Z",
     "start_time": "2025-03-31T18:21:15.382644Z"
    }
   },
   "source": [
    "input_layer = keras.layers.Input(shape=(SEQ_LEN, len(chars)))\n",
    "x = LSTM(128, return_sequences=True)(input_layer)\n",
    "x = LSTM(128, return_sequences=False)(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(256, 'relu')(x)\n",
    "x = keras.layers.Dense(128, 'relu')(x)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "output_layer = keras.layers.Dense(len(chars), activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(input_layer, output_layer)\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.AdamW(), loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"functional_1\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001B[38;5;33mInputLayer\u001B[0m)      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m40\u001B[0m, \u001B[38;5;34m27\u001B[0m)         │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001B[38;5;33mLSTM\u001B[0m)                     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m40\u001B[0m, \u001B[38;5;34m128\u001B[0m)        │        \u001B[38;5;34m79,872\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001B[38;5;33mLSTM\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │       \u001B[38;5;34m131,584\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001B[38;5;33mFlatten\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m)            │        \u001B[38;5;34m33,024\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │        \u001B[38;5;34m32,896\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001B[38;5;33mDropout\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m27\u001B[0m)             │         \u001B[38;5;34m3,483\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">79,872</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,483</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m280,859\u001B[0m (1.07 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">280,859</span> (1.07 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m280,859\u001B[0m (1.07 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">280,859</span> (1.07 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "LRrQ0L5ECWOA",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:33:50.197823Z",
     "start_time": "2025-03-31T18:21:16.097064Z"
    }
   },
   "source": [
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='best.weights.h5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='auto',\n",
    "    save_best_only=True)\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "\n",
    "history = model.fit(X_ohe, y_ohe, validation_split=0.2, callbacks=[model_checkpoint_callback], epochs=epochs,\n",
    "                    batch_size=batch_size)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001B[1m2535/2535\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m83s\u001B[0m 31ms/step - accuracy: 0.2850 - loss: 2.4573 - val_accuracy: 0.4702 - val_loss: 1.7726\n",
      "Epoch 2/10\n",
      "\u001B[1m2535/2535\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m75s\u001B[0m 29ms/step - accuracy: 0.4740 - loss: 1.7512 - val_accuracy: 0.5136 - val_loss: 1.5998\n",
      "Epoch 3/10\n",
      "\u001B[1m2535/2535\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m79s\u001B[0m 31ms/step - accuracy: 0.5219 - loss: 1.5756 - val_accuracy: 0.5416 - val_loss: 1.5180\n",
      "Epoch 4/10\n",
      "\u001B[1m2535/2535\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m70s\u001B[0m 28ms/step - accuracy: 0.5467 - loss: 1.4908 - val_accuracy: 0.5513 - val_loss: 1.4821\n",
      "Epoch 5/10\n",
      "\u001B[1m2535/2535\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m74s\u001B[0m 29ms/step - accuracy: 0.5655 - loss: 1.4305 - val_accuracy: 0.5598 - val_loss: 1.4514\n",
      "Epoch 6/10\n",
      "\u001B[1m2535/2535\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m70s\u001B[0m 27ms/step - accuracy: 0.5758 - loss: 1.3896 - val_accuracy: 0.5662 - val_loss: 1.4324\n",
      "Epoch 7/10\n",
      "\u001B[1m2535/2535\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m74s\u001B[0m 29ms/step - accuracy: 0.5849 - loss: 1.3556 - val_accuracy: 0.5689 - val_loss: 1.4279\n",
      "Epoch 8/10\n",
      "\u001B[1m2535/2535\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m76s\u001B[0m 30ms/step - accuracy: 0.5933 - loss: 1.3244 - val_accuracy: 0.5772 - val_loss: 1.4101\n",
      "Epoch 9/10\n",
      "\u001B[1m2535/2535\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m80s\u001B[0m 32ms/step - accuracy: 0.5971 - loss: 1.3070 - val_accuracy: 0.5765 - val_loss: 1.4106\n",
      "Epoch 10/10\n",
      "\u001B[1m2535/2535\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m74s\u001B[0m 29ms/step - accuracy: 0.6058 - loss: 1.2771 - val_accuracy: 0.5765 - val_loss: 1.4134\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "OUWgOxBvCWOA",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:38:35.609465Z",
     "start_time": "2025-03-31T18:38:35.415226Z"
    }
   },
   "source": [
    "model.load_weights(\"best.weights.h5\")"
   ],
   "outputs": [],
   "execution_count": 84
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "PdUEqCScCWOA",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:38:35.621470Z",
     "start_time": "2025-03-31T18:38:35.615305Z"
    }
   },
   "source": [
    "X_ohe[0].reshape((1, 40, 27))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False, ..., False, False, False],\n",
       "        [ True, False, False, ..., False, False, False],\n",
       "        [False, False, False, ..., False, False, False]]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 85
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "a4b1n3hSCWOA",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:38:36.318896Z",
     "start_time": "2025-03-31T18:38:36.119395Z"
    }
   },
   "source": [
    "y_pred = model.predict(X_ohe[0].reshape((1, 40, 27)))[0]"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 162ms/step\n"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "CilfzlIxCWOB",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:38:36.789545Z",
     "start_time": "2025-03-31T18:38:36.785239Z"
    }
   },
   "source": [
    "y_pred"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.1096086e-05, 1.2925956e-01, 1.5404469e-06, 2.1061169e-04,\n",
       "       1.0520852e-05, 2.3454751e-01, 5.3106937e-06, 3.2084448e-05,\n",
       "       1.5309560e-03, 1.4103056e-01, 5.9268719e-09, 2.8466397e-05,\n",
       "       5.1620300e-04, 9.9390563e-05, 2.1342952e-04, 4.1424966e-01,\n",
       "       4.3848555e-05, 1.4749114e-07, 9.0846242e-03, 5.9176123e-06,\n",
       "       3.7562803e-04, 6.3571796e-02, 1.5650301e-05, 2.9193130e-03,\n",
       "       1.1797243e-09, 2.2229271e-03, 3.2183355e-06], dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 87
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jz-TiD5yCWOB"
   },
   "source": [
    "## 📌 We won't use output probabilities directly\n",
    "* We will sample from the predicted outputs using Temperature Softmax [see this](https://medium.com/@majid.ghafouri/why-should-we-use-temperature-in-softmax-3709f4e0161)\n",
    "\n",
    "* Basically, the ideas is that it would re-weight the probability distribution so that you can control how much surprising (i.e. higher temperature/entropy) or predictable (i.e. lower temperature/entropy) the next selected character would be\n",
    "    * 💡 The concept of *Temperature* is used among many generative models\n",
    "        * e.g. LLMs like [Mixtral-8x7B](https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "mLYsEX_MCWOB",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:38:37.220396Z",
     "start_time": "2025-03-31T18:38:37.217178Z"
    }
   },
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ],
   "outputs": [],
   "execution_count": 88
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "5XHMIKj3CWOB",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:38:37.662666Z",
     "start_time": "2025-03-31T18:38:37.657819Z"
    }
   },
   "source": [
    "c = sample(y_pred)\n",
    "indices_char[c]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'o'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 89
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0A86i-sCWOB"
   },
   "source": [
    "### 💡 To use the model as a next characted generator for given seed text we need to create a feedback loop"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "qtv-rRGHCWOC",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:39:11.589436Z",
     "start_time": "2025-03-31T18:38:38.110652Z"
    }
   },
   "source": [
    "whole_text = X[10].copy()\n",
    "seq = X[10].copy()\n",
    "for i in range(500):\n",
    "    paragraph_ohe = np.zeros((1, SEQ_LEN, len(chars)))\n",
    "    for t, char in enumerate(seq):\n",
    "        paragraph_ohe[0, t, char_indices[char]] = 1\n",
    "    y_pred = model.predict(paragraph_ohe)\n",
    "    c = sample(y_pred[0], 0.5)\n",
    "    next_char = indices_char[c]\n",
    "    whole_text.append(next_char)\n",
    "    seq = whole_text[-SEQ_LEN:]"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 195ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 50ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 52ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 58ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 55ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 61ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 61ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m-2s\u001B[0m -2301886us/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 51ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 60ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 59ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 71ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 51ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 76ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 73ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 64ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 54ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 69ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 78ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 72ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 56ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 58ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 56ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 72ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 84ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 65ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 47ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 52ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 52ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 52ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 70ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 46ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 54ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 59ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 54ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 74ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 64ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 61ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 61ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 72ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 54ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 62ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 58ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 63ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 43ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 304ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 42ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m-2s\u001B[0m -2257778us/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 41ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 78ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 34ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 37ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 39ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 68ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 49ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 84ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 56ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 45ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 35ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 44ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 61ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 38ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 40ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 36ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 28ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 32ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 31ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 30ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 33ms/step\n"
     ]
    }
   ],
   "execution_count": 90
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CMTzF2X5CWOC"
   },
   "source": [
    "#### You can see that the model has only seen character-level data however it has learnt to generate existing words/phrases\n",
    "* And yes, the output is still far from ideal 🙂\n",
    "* 🔎 How would you make it better?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "id": "3PRLg61JCWOC",
    "ExecuteTime": {
     "end_time": "2025-03-31T18:42:08.646502Z",
     "start_time": "2025-03-31T18:42:08.642140Z"
    }
   },
   "source": [
    "''.join(whole_text)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'o livedmr and mrs dursley of number four family and he was here and said like the best back the stone well a fair the chooler who are the potion they were you were you can not to the sorting and which was a lot of the chasers he was down them to get his anger the way the ear and the transfist they were said hagrid and hermione said harry they couldnt see his hand and they was starting the troll dear from the side and a lunches of hereyou be the portraits with his seat and they were the door started to the classes and last his on the d'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 91
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UFCTsXhTCWOC"
   },
   "source": [
    "# ✅  Tasks for the lecture\n",
    "* Homework's on vacation mode thanks to the amount of new topics in this lecture, enjoy the break 🙂\n",
    "\n",
    "Svoboda is homie."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
